{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_last_msg_id": "b37997c83b00472cb5d409e735ec5c03"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.core import LightningModule\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers.tensorboard import TensorBoardLogger\n",
    "\n",
    "sys.path.append('../..')\n",
    "from lib.schedulers import DelayedScheduler\n",
    "from lib.dataloaders import PatchesDataset\n",
    "from lib.datasets import (actual_lbl_nums, \n",
    "                          patches_rgb_mean_av1, patches_rgb_std_av1, \n",
    "                          get_train_test_img_ids_split)\n",
    "from lib.dataloaders import PatchesDataset\n",
    "from lib.trainers import PatchesModule\n",
    "from lib.augmentations import augment_empty, augment_v1\n",
    "from lib.losses import SmoothLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_last_msg_id": "45a4fd1547454703b4b60493412bf597"
   },
   "outputs": [],
   "source": [
    "class MyModule(PatchesModule):\n",
    "    def __init__(self, model, hparams, num_workers=0, log_train_every_batch=False):\n",
    "        super().__init__(model, hparams, num_workers, log_train_every_batch)\n",
    "        self.hparams = hparams\n",
    "        self.model = model\n",
    "        self.num_workers = num_workers\n",
    "        self.log_train_every_batch = log_train_every_batch\n",
    "        \n",
    "        self.dec_loss = nn.MSELoss()\n",
    "        self.mask_loss = SmoothLoss(nn.KLDivLoss(), smoothing=0.2, one_hot_target=True)\n",
    "        self.lbl_loss = SmoothLoss(nn.KLDivLoss(), smoothing=0.2, one_hot_target=False)\n",
    "\n",
    "        self.loss_weights = {\n",
    "            'dec': 1/3,\n",
    "            'mask': 1/3,\n",
    "            'label': 1/3\n",
    "        }\n",
    "\n",
    "    def _loss(self, o_masks, o_labels, o_imgs, masks, labels, imgs, n_imgs, provider):\n",
    "        pr0_idx = provider == 0\n",
    "        pr1_idx = provider == 1\n",
    "\n",
    "        dec_loss = self.dec_loss(o_imgs, imgs)\n",
    "        \n",
    "        tmp = masks[pr1_idx]-6\n",
    "        if tmp.max() > 3 or tmp.min() < 0:\n",
    "            assert f\"WTF {tmp.max()}, {tmp.min()} !!!\"\n",
    "\n",
    "        mask_loss = (self.mask_loss(o_masks[pr0_idx, :6], masks[pr0_idx]) +\n",
    "            self.mask_loss(o_masks[pr1_idx, -3:], masks[pr1_idx]-6))\n",
    "\n",
    "        label_loss = (self.lbl_loss(o_labels[pr0_idx, :6], labels[pr0_idx, :6]) +\n",
    "            self.lbl_loss(o_labels[pr1_idx, -3:], labels[pr1_idx, -3:]))\n",
    "\n",
    "        loss = (self.loss_weights['dec'] * dec_loss +\n",
    "                self.loss_weights['mask'] * mask_loss +\n",
    "                self.loss_weights['label'] * label_loss)\n",
    "\n",
    "        return loss, dec_loss, mask_loss, label_loss\n",
    "    \n",
    "    def step(self, batch, batch_idx, is_train):\n",
    "        imgs, masks, labels, provider, isup_grade, g_score = batch\n",
    "        b = imgs.shape[0]\n",
    "        n_imgs = imgs - self.rgb_mean / self.rgb_std\n",
    "                \n",
    "        o_masks, o_labels, o_imgs = self(n_imgs)\n",
    "        \n",
    "        loss, dec_loss, mask_loss, label_loss =\\\n",
    "            self._loss(o_masks, o_labels, o_imgs, masks, labels, imgs, n_imgs, provider)\n",
    "\n",
    "        lbl_acc = self._accuracy(o_labels, labels.argmax(dim=1))\n",
    "        mask_acc = self._accuracy(o_masks.view(b, actual_lbl_nums, -1), \n",
    "                                  masks.view(b, -1))\n",
    "        \n",
    "        lr = self.optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        pr = '' if is_train else 'val_'\n",
    "        \n",
    "        log_dict = {\n",
    "            pr+'loss': loss.item(), \n",
    "            pr+'dec_loss': dec_loss.item(), \n",
    "            pr+'mask_loss': mask_loss.item(), \n",
    "            pr+'label_loss': label_loss.item(),\n",
    "            pr+'lbl_acc': lbl_acc.item(),\n",
    "            pr+'mask_acc': mask_acc.item(),\n",
    "            pr+'lr': lr\n",
    "        }\n",
    "        \n",
    "        if is_train and self.log_train_every_batch:\n",
    "            return {'loss': loss, 'log': log_dict}\n",
    "        else:\n",
    "            return log_dict    \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, batch_idx, True)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, batch_idx, False)\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        self.rgb_mean, self.rgb_std = (torch.tensor(patches_rgb_mean_av1, dtype=torch.float32), \n",
    "                                       torch.tensor(patches_rgb_std_av1, dtype=torch.float32))\n",
    "        self.train_img_ids, self.test_img_ids = get_train_test_img_ids_split()\n",
    "        \n",
    "    def _apply(self, fn):\n",
    "        self = super()._apply(fn)\n",
    "        self.rgb_mean = fn(self.rgb_mean)\n",
    "        self.rgb_std = fn(self.rgb_std)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            PatchesDataset(self.train_img_ids, transform=augment_v1, \n",
    "                           scale=self.hparams['dataset']['scale'], load_masks=True),\n",
    "            batch_size=self.hparams['batch_size'], shuffle=True,\n",
    "            num_workers=self.num_workers, pin_memory=True,\n",
    "        )\n",
    "        \n",
    "        self.steps_in_batch = len(train_loader)\n",
    "        \n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            PatchesDataset(self.test_img_ids, transform=augment_empty, \n",
    "                           scale=self.hparams['dataset']['scale'], load_masks=True),\n",
    "            batch_size=self.hparams['batch_size'], shuffle=False, \n",
    "            num_workers=self.num_workers, pin_memory=True,\n",
    "        )\n",
    "        \n",
    "        return val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_last_msg_id": "b536ce8b7d084e89ad21d2cce79fa102"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from segmentation_models_pytorch.encoders import get_encoder, get_encoder_names, encoders\n",
    "from segmentation_models_pytorch.unet import Unet\n",
    "import segmentation_models_pytorch\n",
    "\n",
    "from segmentation_models_pytorch.unet.decoder import DecoderBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_last_msg_id": "4cbc3ffb06f441b9818a57c414536862"
   },
   "outputs": [],
   "source": [
    "# activation для масок не забыть!!!\n",
    "model = Unet('resnet18', encoder_weights=None, \n",
    "             activation='logsoftmax',\n",
    "             classes=actual_lbl_nums, \n",
    "             aux_params={\n",
    "                 'classes': actual_lbl_nums, \n",
    "                 'activation': 'logsoftmax'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_last_msg_id": "cb3b9a96ebe247dd9395b43e2d003c2f"
   },
   "outputs": [],
   "source": [
    "class AutoDecoder(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            channels,\n",
    "            use_batchnorm=True,\n",
    "            attention_type=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        in_channels = channels[:0:-1]\n",
    "        out_channels = channels[-2::-1]        \n",
    "        \n",
    "        kwargs = dict(use_batchnorm=use_batchnorm, attention_type=attention_type)        \n",
    "        blocks = [\n",
    "            DecoderBlock(in_ch, 0, out_ch, **kwargs)\n",
    "            for in_ch, out_ch in zip(in_channels, out_channels)\n",
    "        ]\n",
    "        self.blocks = nn.ModuleList(blocks)\n",
    "\n",
    "    def forward(self, features):\n",
    "        x = features\n",
    "        \n",
    "        for i, decoder_block in enumerate(self.blocks):\n",
    "            x = decoder_block(x)\n",
    "            \n",
    "        x = torch.sigmoid(x)\n",
    "        # x = torch.tanh(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "import types\n",
    "\n",
    "def forward(self, x):\n",
    "    \"\"\"Sequentially pass `x` trough model`s encoder, decoder and heads\"\"\"\n",
    "    features = self.encoder(x)\n",
    "    decoder_output = self.decoder(*features)\n",
    "    masks = self.segmentation_head(decoder_output)\n",
    "    \n",
    "    out = masks\n",
    "\n",
    "    if self.classification_head is not None:\n",
    "        labels = self.classification_head(features[-1])\n",
    "        out = (masks, labels)\n",
    "    \n",
    "    if self.autodecoder is not None:\n",
    "        decoded = self.autodecoder(features[-1])\n",
    "        out = (masks, labels, decoded)\n",
    "\n",
    "    return out\n",
    "\n",
    "model.forward = types.MethodType(forward, model)\n",
    "channels = model.encoder.out_channels\n",
    "model.autodecoder = AutoDecoder(channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_last_msg_id": "83ab8cd001214213ba589e14d884ae91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16734015"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.data.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_last_msg_id": "e0fbfa0fc0d54b5d88f9ae6f15f50333"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2400029"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.data.numel() for p in model.autodecoder.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DelayedScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_last_msg_id": "e194001ecee2480680aba8d2224d4466"
   },
   "outputs": [],
   "source": [
    "batches_in_epoch = 34362\n",
    "\n",
    "epochs = 2\n",
    "# warmup_epochs = 1\n",
    "warmup_epochs = 0\n",
    "warmup_steps = 3000\n",
    "batch_size = 58\n",
    "hparams = {\n",
    "    'batch_size': batch_size,\n",
    "    'learning_rate': 0.1 * batch_size / 256,\n",
    "    'dataset': {'scale': 0.5},\n",
    "    'optimizer': {\n",
    "        'name': 'SGD', \n",
    "        'params': {\n",
    "            'momentum': 0.9, \n",
    "            'weight_decay': 1e-4\n",
    "        }\n",
    "    },\n",
    "    'scheduler': {\n",
    "        'name': 'CosineAnnealingLR',\n",
    "        'params': {\n",
    "            # 'T_max': (epochs-warmup_epochs) * batches_in_epoch\n",
    "            'T_max': epochs * batches_in_epoch - warmup_steps\n",
    "        },\n",
    "        'interval': 'step'\n",
    "    },\n",
    "    # 'warmup_epochs': warmup_epochs,\n",
    "    'warmup_steps': warmup_steps,\n",
    "    'steps_in_batch': batches_in_epoch,\n",
    "    'epochs': epochs\n",
    "}\n",
    "module = MyModule(model, hparams, num_workers=12, log_train_every_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_last_msg_id": "854ddf7d47db40da80b4acae2962b925"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:GPU available: True, used: True\n",
      "INFO:lightning:CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "logger = TensorBoardLogger(\n",
    "    os.getcwd(), 'Patches256TestRun',\n",
    ")\n",
    "# accumulate_grad_batches=1\n",
    "trainer = Trainer(logger, max_epochs=epochs, gpus=[0,], fast_dev_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_last_msg_id": "e156b4e090104a0da373e41f36a53e1d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Start tensorboard.\n",
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir ./Patches256TestRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_last_msg_id": "c4026c30ae9b4b40890135d2042d2ea8"
   },
   "outputs": [],
   "source": [
    "g_batch = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_last_msg_id": "ce38b3912f764c119c183fcdff844c55",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:\n",
      "    | Name                                            | Type               | Params\n",
      "-----------------------------------------------------------------------------------\n",
      "0   | model                                           | Unet               | 16 M  \n",
      "1   | model.encoder                                   | ResNetEncoder      | 11 M  \n",
      "2   | model.encoder.conv1                             | Conv2d             | 9 K   \n",
      "3   | model.encoder.bn1                               | BatchNorm2d        | 128   \n",
      "4   | model.encoder.relu                              | ReLU               | 0     \n",
      "5   | model.encoder.maxpool                           | MaxPool2d          | 0     \n",
      "6   | model.encoder.layer1                            | Sequential         | 147 K \n",
      "7   | model.encoder.layer1.0                          | BasicBlock         | 73 K  \n",
      "8   | model.encoder.layer1.0.conv1                    | Conv2d             | 36 K  \n",
      "9   | model.encoder.layer1.0.bn1                      | BatchNorm2d        | 128   \n",
      "10  | model.encoder.layer1.0.relu                     | ReLU               | 0     \n",
      "11  | model.encoder.layer1.0.conv2                    | Conv2d             | 36 K  \n",
      "12  | model.encoder.layer1.0.bn2                      | BatchNorm2d        | 128   \n",
      "13  | model.encoder.layer1.1                          | BasicBlock         | 73 K  \n",
      "14  | model.encoder.layer1.1.conv1                    | Conv2d             | 36 K  \n",
      "15  | model.encoder.layer1.1.bn1                      | BatchNorm2d        | 128   \n",
      "16  | model.encoder.layer1.1.relu                     | ReLU               | 0     \n",
      "17  | model.encoder.layer1.1.conv2                    | Conv2d             | 36 K  \n",
      "18  | model.encoder.layer1.1.bn2                      | BatchNorm2d        | 128   \n",
      "19  | model.encoder.layer2                            | Sequential         | 525 K \n",
      "20  | model.encoder.layer2.0                          | BasicBlock         | 230 K \n",
      "21  | model.encoder.layer2.0.conv1                    | Conv2d             | 73 K  \n",
      "22  | model.encoder.layer2.0.bn1                      | BatchNorm2d        | 256   \n",
      "23  | model.encoder.layer2.0.relu                     | ReLU               | 0     \n",
      "24  | model.encoder.layer2.0.conv2                    | Conv2d             | 147 K \n",
      "25  | model.encoder.layer2.0.bn2                      | BatchNorm2d        | 256   \n",
      "26  | model.encoder.layer2.0.downsample               | Sequential         | 8 K   \n",
      "27  | model.encoder.layer2.0.downsample.0             | Conv2d             | 8 K   \n",
      "28  | model.encoder.layer2.0.downsample.1             | BatchNorm2d        | 256   \n",
      "29  | model.encoder.layer2.1                          | BasicBlock         | 295 K \n",
      "30  | model.encoder.layer2.1.conv1                    | Conv2d             | 147 K \n",
      "31  | model.encoder.layer2.1.bn1                      | BatchNorm2d        | 256   \n",
      "32  | model.encoder.layer2.1.relu                     | ReLU               | 0     \n",
      "33  | model.encoder.layer2.1.conv2                    | Conv2d             | 147 K \n",
      "34  | model.encoder.layer2.1.bn2                      | BatchNorm2d        | 256   \n",
      "35  | model.encoder.layer3                            | Sequential         | 2 M   \n",
      "36  | model.encoder.layer3.0                          | BasicBlock         | 919 K \n",
      "37  | model.encoder.layer3.0.conv1                    | Conv2d             | 294 K \n",
      "38  | model.encoder.layer3.0.bn1                      | BatchNorm2d        | 512   \n",
      "39  | model.encoder.layer3.0.relu                     | ReLU               | 0     \n",
      "40  | model.encoder.layer3.0.conv2                    | Conv2d             | 589 K \n",
      "41  | model.encoder.layer3.0.bn2                      | BatchNorm2d        | 512   \n",
      "42  | model.encoder.layer3.0.downsample               | Sequential         | 33 K  \n",
      "43  | model.encoder.layer3.0.downsample.0             | Conv2d             | 32 K  \n",
      "44  | model.encoder.layer3.0.downsample.1             | BatchNorm2d        | 512   \n",
      "45  | model.encoder.layer3.1                          | BasicBlock         | 1 M   \n",
      "46  | model.encoder.layer3.1.conv1                    | Conv2d             | 589 K \n",
      "47  | model.encoder.layer3.1.bn1                      | BatchNorm2d        | 512   \n",
      "48  | model.encoder.layer3.1.relu                     | ReLU               | 0     \n",
      "49  | model.encoder.layer3.1.conv2                    | Conv2d             | 589 K \n",
      "50  | model.encoder.layer3.1.bn2                      | BatchNorm2d        | 512   \n",
      "51  | model.encoder.layer4                            | Sequential         | 8 M   \n",
      "52  | model.encoder.layer4.0                          | BasicBlock         | 3 M   \n",
      "53  | model.encoder.layer4.0.conv1                    | Conv2d             | 1 M   \n",
      "54  | model.encoder.layer4.0.bn1                      | BatchNorm2d        | 1 K   \n",
      "55  | model.encoder.layer4.0.relu                     | ReLU               | 0     \n",
      "56  | model.encoder.layer4.0.conv2                    | Conv2d             | 2 M   \n",
      "57  | model.encoder.layer4.0.bn2                      | BatchNorm2d        | 1 K   \n",
      "58  | model.encoder.layer4.0.downsample               | Sequential         | 132 K \n",
      "59  | model.encoder.layer4.0.downsample.0             | Conv2d             | 131 K \n",
      "60  | model.encoder.layer4.0.downsample.1             | BatchNorm2d        | 1 K   \n",
      "61  | model.encoder.layer4.1                          | BasicBlock         | 4 M   \n",
      "62  | model.encoder.layer4.1.conv1                    | Conv2d             | 2 M   \n",
      "63  | model.encoder.layer4.1.bn1                      | BatchNorm2d        | 1 K   \n",
      "64  | model.encoder.layer4.1.relu                     | ReLU               | 0     \n",
      "65  | model.encoder.layer4.1.conv2                    | Conv2d             | 2 M   \n",
      "66  | model.encoder.layer4.1.bn2                      | BatchNorm2d        | 1 K   \n",
      "67  | model.encoder.avgpool                           | AdaptiveAvgPool2d  | 0     \n",
      "68  | model.decoder                                   | UnetDecoder        | 3 M   \n",
      "69  | model.decoder.center                            | Identity           | 0     \n",
      "70  | model.decoder.blocks                            | ModuleList         | 3 M   \n",
      "71  | model.decoder.blocks.0                          | DecoderBlock       | 2 M   \n",
      "72  | model.decoder.blocks.0.conv1                    | Conv2dReLU         | 1 M   \n",
      "73  | model.decoder.blocks.0.conv1.0                  | Conv2d             | 1 M   \n",
      "74  | model.decoder.blocks.0.conv1.1                  | BatchNorm2d        | 512   \n",
      "75  | model.decoder.blocks.0.conv1.2                  | ReLU               | 0     \n",
      "76  | model.decoder.blocks.0.attention1               | Attention          | 0     \n",
      "77  | model.decoder.blocks.0.attention1.attention     | Identity           | 0     \n",
      "78  | model.decoder.blocks.0.conv2                    | Conv2dReLU         | 590 K \n",
      "79  | model.decoder.blocks.0.conv2.0                  | Conv2d             | 589 K \n",
      "80  | model.decoder.blocks.0.conv2.1                  | BatchNorm2d        | 512   \n",
      "81  | model.decoder.blocks.0.conv2.2                  | ReLU               | 0     \n",
      "82  | model.decoder.blocks.0.attention2               | Attention          | 0     \n",
      "83  | model.decoder.blocks.0.attention2.attention     | Identity           | 0     \n",
      "84  | model.decoder.blocks.1                          | DecoderBlock       | 590 K \n",
      "85  | model.decoder.blocks.1.conv1                    | Conv2dReLU         | 442 K \n",
      "86  | model.decoder.blocks.1.conv1.0                  | Conv2d             | 442 K \n",
      "87  | model.decoder.blocks.1.conv1.1                  | BatchNorm2d        | 256   \n",
      "88  | model.decoder.blocks.1.conv1.2                  | ReLU               | 0     \n",
      "89  | model.decoder.blocks.1.attention1               | Attention          | 0     \n",
      "90  | model.decoder.blocks.1.attention1.attention     | Identity           | 0     \n",
      "91  | model.decoder.blocks.1.conv2                    | Conv2dReLU         | 147 K \n",
      "92  | model.decoder.blocks.1.conv2.0                  | Conv2d             | 147 K \n",
      "93  | model.decoder.blocks.1.conv2.1                  | BatchNorm2d        | 256   \n",
      "94  | model.decoder.blocks.1.conv2.2                  | ReLU               | 0     \n",
      "95  | model.decoder.blocks.1.attention2               | Attention          | 0     \n",
      "96  | model.decoder.blocks.1.attention2.attention     | Identity           | 0     \n",
      "97  | model.decoder.blocks.2                          | DecoderBlock       | 147 K \n",
      "98  | model.decoder.blocks.2.conv1                    | Conv2dReLU         | 110 K \n",
      "99  | model.decoder.blocks.2.conv1.0                  | Conv2d             | 110 K \n",
      "100 | model.decoder.blocks.2.conv1.1                  | BatchNorm2d        | 128   \n",
      "101 | model.decoder.blocks.2.conv1.2                  | ReLU               | 0     \n",
      "102 | model.decoder.blocks.2.attention1               | Attention          | 0     \n",
      "103 | model.decoder.blocks.2.attention1.attention     | Identity           | 0     \n",
      "104 | model.decoder.blocks.2.conv2                    | Conv2dReLU         | 36 K  \n",
      "105 | model.decoder.blocks.2.conv2.0                  | Conv2d             | 36 K  \n",
      "106 | model.decoder.blocks.2.conv2.1                  | BatchNorm2d        | 128   \n",
      "107 | model.decoder.blocks.2.conv2.2                  | ReLU               | 0     \n",
      "108 | model.decoder.blocks.2.attention2               | Attention          | 0     \n",
      "109 | model.decoder.blocks.2.attention2.attention     | Identity           | 0     \n",
      "110 | model.decoder.blocks.3                          | DecoderBlock       | 46 K  \n",
      "111 | model.decoder.blocks.3.conv1                    | Conv2dReLU         | 36 K  \n",
      "112 | model.decoder.blocks.3.conv1.0                  | Conv2d             | 36 K  \n",
      "113 | model.decoder.blocks.3.conv1.1                  | BatchNorm2d        | 64    \n",
      "114 | model.decoder.blocks.3.conv1.2                  | ReLU               | 0     \n",
      "115 | model.decoder.blocks.3.attention1               | Attention          | 0     \n",
      "116 | model.decoder.blocks.3.attention1.attention     | Identity           | 0     \n",
      "117 | model.decoder.blocks.3.conv2                    | Conv2dReLU         | 9 K   \n",
      "118 | model.decoder.blocks.3.conv2.0                  | Conv2d             | 9 K   \n",
      "119 | model.decoder.blocks.3.conv2.1                  | BatchNorm2d        | 64    \n",
      "120 | model.decoder.blocks.3.conv2.2                  | ReLU               | 0     \n",
      "121 | model.decoder.blocks.3.attention2               | Attention          | 0     \n",
      "122 | model.decoder.blocks.3.attention2.attention     | Identity           | 0     \n",
      "123 | model.decoder.blocks.4                          | DecoderBlock       | 6 K   \n",
      "124 | model.decoder.blocks.4.conv1                    | Conv2dReLU         | 4 K   \n",
      "125 | model.decoder.blocks.4.conv1.0                  | Conv2d             | 4 K   \n",
      "126 | model.decoder.blocks.4.conv1.1                  | BatchNorm2d        | 32    \n",
      "127 | model.decoder.blocks.4.conv1.2                  | ReLU               | 0     \n",
      "128 | model.decoder.blocks.4.attention1               | Attention          | 0     \n",
      "129 | model.decoder.blocks.4.attention1.attention     | Identity           | 0     \n",
      "130 | model.decoder.blocks.4.conv2                    | Conv2dReLU         | 2 K   \n",
      "131 | model.decoder.blocks.4.conv2.0                  | Conv2d             | 2 K   \n",
      "132 | model.decoder.blocks.4.conv2.1                  | BatchNorm2d        | 32    \n",
      "133 | model.decoder.blocks.4.conv2.2                  | ReLU               | 0     \n",
      "134 | model.decoder.blocks.4.attention2               | Attention          | 0     \n",
      "135 | model.decoder.blocks.4.attention2.attention     | Identity           | 0     \n",
      "136 | model.segmentation_head                         | SegmentationHead   | 1 K   \n",
      "137 | model.segmentation_head.0                       | Conv2d             | 1 K   \n",
      "138 | model.segmentation_head.1                       | Identity           | 0     \n",
      "139 | model.segmentation_head.2                       | Activation         | 0     \n",
      "140 | model.segmentation_head.2.activation            | LogSoftmax         | 0     \n",
      "141 | model.classification_head                       | ClassificationHead | 4 K   \n",
      "142 | model.classification_head.0                     | AdaptiveAvgPool2d  | 0     \n",
      "143 | model.classification_head.1                     | Flatten            | 0     \n",
      "144 | model.classification_head.2                     | Dropout            | 0     \n",
      "145 | model.classification_head.3                     | Linear             | 4 K   \n",
      "146 | model.classification_head.4                     | Activation         | 0     \n",
      "147 | model.classification_head.4.activation          | LogSoftmax         | 0     \n",
      "148 | model.autodecoder                               | AutoDecoder        | 2 M   \n",
      "149 | model.autodecoder.blocks                        | ModuleList         | 2 M   \n",
      "150 | model.autodecoder.blocks.0                      | DecoderBlock       | 1 M   \n",
      "151 | model.autodecoder.blocks.0.conv1                | Conv2dReLU         | 1 M   \n",
      "152 | model.autodecoder.blocks.0.conv1.0              | Conv2d             | 1 M   \n",
      "153 | model.autodecoder.blocks.0.conv1.1              | BatchNorm2d        | 512   \n",
      "154 | model.autodecoder.blocks.0.conv1.2              | ReLU               | 0     \n",
      "155 | model.autodecoder.blocks.0.attention1           | Attention          | 0     \n",
      "156 | model.autodecoder.blocks.0.attention1.attention | Identity           | 0     \n",
      "157 | model.autodecoder.blocks.0.conv2                | Conv2dReLU         | 590 K \n",
      "158 | model.autodecoder.blocks.0.conv2.0              | Conv2d             | 589 K \n",
      "159 | model.autodecoder.blocks.0.conv2.1              | BatchNorm2d        | 512   \n",
      "160 | model.autodecoder.blocks.0.conv2.2              | ReLU               | 0     \n",
      "161 | model.autodecoder.blocks.0.attention2           | Attention          | 0     \n",
      "162 | model.autodecoder.blocks.0.attention2.attention | Identity           | 0     \n",
      "163 | model.autodecoder.blocks.1                      | DecoderBlock       | 442 K \n",
      "164 | model.autodecoder.blocks.1.conv1                | Conv2dReLU         | 295 K \n",
      "165 | model.autodecoder.blocks.1.conv1.0              | Conv2d             | 294 K \n",
      "166 | model.autodecoder.blocks.1.conv1.1              | BatchNorm2d        | 256   \n",
      "167 | model.autodecoder.blocks.1.conv1.2              | ReLU               | 0     \n",
      "168 | model.autodecoder.blocks.1.attention1           | Attention          | 0     \n",
      "169 | model.autodecoder.blocks.1.attention1.attention | Identity           | 0     \n",
      "170 | model.autodecoder.blocks.1.conv2                | Conv2dReLU         | 147 K \n",
      "171 | model.autodecoder.blocks.1.conv2.0              | Conv2d             | 147 K \n",
      "172 | model.autodecoder.blocks.1.conv2.1              | BatchNorm2d        | 256   \n",
      "173 | model.autodecoder.blocks.1.conv2.2              | ReLU               | 0     \n",
      "174 | model.autodecoder.blocks.1.attention2           | Attention          | 0     \n",
      "175 | model.autodecoder.blocks.1.attention2.attention | Identity           | 0     \n",
      "176 | model.autodecoder.blocks.2                      | DecoderBlock       | 110 K \n",
      "177 | model.autodecoder.blocks.2.conv1                | Conv2dReLU         | 73 K  \n",
      "178 | model.autodecoder.blocks.2.conv1.0              | Conv2d             | 73 K  \n",
      "179 | model.autodecoder.blocks.2.conv1.1              | BatchNorm2d        | 128   \n",
      "180 | model.autodecoder.blocks.2.conv1.2              | ReLU               | 0     \n",
      "181 | model.autodecoder.blocks.2.attention1           | Attention          | 0     \n",
      "182 | model.autodecoder.blocks.2.attention1.attention | Identity           | 0     \n",
      "183 | model.autodecoder.blocks.2.conv2                | Conv2dReLU         | 36 K  \n",
      "184 | model.autodecoder.blocks.2.conv2.0              | Conv2d             | 36 K  \n",
      "185 | model.autodecoder.blocks.2.conv2.1              | BatchNorm2d        | 128   \n",
      "186 | model.autodecoder.blocks.2.conv2.2              | ReLU               | 0     \n",
      "187 | model.autodecoder.blocks.2.attention2           | Attention          | 0     \n",
      "188 | model.autodecoder.blocks.2.attention2.attention | Identity           | 0     \n",
      "189 | model.autodecoder.blocks.3                      | DecoderBlock       | 73 K  \n",
      "190 | model.autodecoder.blocks.3.conv1                | Conv2dReLU         | 36 K  \n",
      "191 | model.autodecoder.blocks.3.conv1.0              | Conv2d             | 36 K  \n",
      "192 | model.autodecoder.blocks.3.conv1.1              | BatchNorm2d        | 128   \n",
      "193 | model.autodecoder.blocks.3.conv1.2              | ReLU               | 0     \n",
      "194 | model.autodecoder.blocks.3.attention1           | Attention          | 0     \n",
      "195 | model.autodecoder.blocks.3.attention1.attention | Identity           | 0     \n",
      "196 | model.autodecoder.blocks.3.conv2                | Conv2dReLU         | 36 K  \n",
      "197 | model.autodecoder.blocks.3.conv2.0              | Conv2d             | 36 K  \n",
      "198 | model.autodecoder.blocks.3.conv2.1              | BatchNorm2d        | 128   \n",
      "199 | model.autodecoder.blocks.3.conv2.2              | ReLU               | 0     \n",
      "200 | model.autodecoder.blocks.3.attention2           | Attention          | 0     \n",
      "201 | model.autodecoder.blocks.3.attention2.attention | Identity           | 0     \n",
      "202 | model.autodecoder.blocks.4                      | DecoderBlock       | 1 K   \n",
      "203 | model.autodecoder.blocks.4.conv1                | Conv2dReLU         | 1 K   \n",
      "204 | model.autodecoder.blocks.4.conv1.0              | Conv2d             | 1 K   \n",
      "205 | model.autodecoder.blocks.4.conv1.1              | BatchNorm2d        | 6     \n",
      "206 | model.autodecoder.blocks.4.conv1.2              | ReLU               | 0     \n",
      "207 | model.autodecoder.blocks.4.attention1           | Attention          | 0     \n",
      "208 | model.autodecoder.blocks.4.attention1.attention | Identity           | 0     \n",
      "209 | model.autodecoder.blocks.4.conv2                | Conv2dReLU         | 87    \n",
      "210 | model.autodecoder.blocks.4.conv2.0              | Conv2d             | 81    \n",
      "211 | model.autodecoder.blocks.4.conv2.1              | BatchNorm2d        | 6     \n",
      "212 | model.autodecoder.blocks.4.conv2.2              | ReLU               | 0     \n",
      "213 | model.autodecoder.blocks.4.attention2           | Attention          | 0     \n",
      "214 | model.autodecoder.blocks.4.attention2.attention | Identity           | 0     \n",
      "215 | dec_loss                                        | MSELoss            | 0     \n",
      "216 | mask_loss                                       | SmoothLoss         | 0     \n",
      "217 | mask_loss.criterion                             | KLDivLoss          | 0     \n",
      "218 | lbl_loss                                        | SmoothLoss         | 0     \n",
      "219 | lbl_loss.criterion                              | KLDivLoss          | 0     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'interval': 'step', 'scheduler': <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f939c20db10>}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/anaconda3/lib/python3.7/site-packages/segmentation_models_pytorch/base/modules.py:89: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.activation(x)\n",
      "/home/ruslan/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1958: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "/home/ruslan/anaconda3/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:23: RuntimeWarning: Displayed epoch numbers in the progress bar start from \"1\" until v0.6.x, but will start from \"0\" in v0.8.0.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0794ace1c959446d9a6229619254c0f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 960.00 MiB (GPU 0; 10.91 GiB total capacity; 8.44 GiB already allocated; 852.38 MiB free; 9.54 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-77a0f6b8a77c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"last.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_gpu_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tpu\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no-cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/distrib_parts.py\u001b[0m in \u001b[0;36msingle_gpu_train\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pretrain_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtpu_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpu_core_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_pretrain_routine\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;31m# CORE TRAINING LOOP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloaders\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0;31m# RUN TNG EPOCH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0;31m# -----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                 \u001b[0;31m# update LR schedulers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0;31m# RUN TRAIN STEP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0;31m# ---------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m             \u001b[0m_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m             \u001b[0mbatch_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm_dic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_step_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_batch\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m                 \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                 \u001b[0;31m# check if loss or model weights are nan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36moptimizer_closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    575\u001b[0m                     \u001b[0mmodel_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_backward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m                         \u001b[0mmodel_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m                     \u001b[0;31m# track metrics for callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/core/hooks.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, trainer, loss, optimizer, optimizer_idx)\u001b[0m\n\u001b[1;32m    153\u001b[0m                     \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 960.00 MiB (GPU 0; 10.91 GiB total capacity; 8.44 GiB already allocated; 852.38 MiB free; 9.54 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "trainer.fit(module)\n",
    "trainer.save_checkpoint(os.path.join(trainer.checkpoint_callback.dirpath, \"last.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_last_msg_id": "04ae3020c84544ea8c278a6814aedc9c"
   },
   "outputs": [],
   "source": [
    "#!rm -r lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_last_msg_id": "622c4b27a18d44ca98bcb5c3dc0411e8"
   },
   "outputs": [],
   "source": [
    "# trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_last_msg_id": "11a8236182b344808f04a67d51721bd7"
   },
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "# metrics.cohen_kappa_score(y, X_p, weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_last_msg_id": "69bda0010bc746748286d5b69c5bf664"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "@dataclass\n",
    "class KappaScore(ConfusionMatrix):\n",
    "    \"Computes the rate of agreement (Cohens Kappa).\"\n",
    "    weights:Optional[str]=None      # None, `linear`, or `quadratic`\n",
    "\n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        sum0 = self.cm.sum(dim=0)\n",
    "        sum1 = self.cm.sum(dim=1)\n",
    "        expected = torch.einsum('i,j->ij', (sum0, sum1)) / sum0.sum()\n",
    "        if self.weights is None:\n",
    "            w = torch.ones((self.n_classes, self.n_classes))\n",
    "            w[self.x, self.x] = 0\n",
    "        elif self.weights == \"linear\" or self.weights == \"quadratic\":\n",
    "            w = torch.zeros((self.n_classes, self.n_classes))\n",
    "            w += torch.arange(self.n_classes, dtype=torch.float)\n",
    "            w = torch.abs(w - torch.t(w)) if self.weights == \"linear\" else (w - torch.t(w)) ** 2\n",
    "        else: raise ValueError('Unknown weights. Expected None, \"linear\", or \"quadratic\".')\n",
    "        k = torch.sum(w * self.cm) / torch.sum(w * expected)\n",
    "        return add_metrics(last_metrics, 1-k)\n",
    "        \n",
    "        \n",
    "        #self.optimizer = optim.SGD(\n",
    "        #    self.parameters(),\n",
    "        #    lr=self.hparams['learning_rate'],\n",
    "        #    momentum=self.hparams['momentum'],\n",
    "        #    weight_decay=self.hparams['weight_decay']\n",
    "        #)\n",
    "        \n",
    "        self.optimizer = optim.Adam(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams['learning_rate'],\n",
    "            weight_decay=self.hparams['weight_decay']\n",
    "        )        \n",
    "        self.scheduler = DelayedScheduler(self.optimizer, self.hparams['sched_warmup_epoch'], \n",
    "            torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, \n",
    "                                                       self.hparams['epochs']-self.hparams['sched_warmup_epoch']))\n",
    "        #self.scheduler = torch.optim.lr_scheduler.MultiStepLR(self.optimizer, \n",
    "        #                                                      milestones=[100, 150], \n",
    "        #                                                      last_epoch=-1)\n",
    "        #self.scheduler = torch.optim.lr_scheduler.ExponentialLR(self.optimizer, \n",
    "        #                                                        gamma=self.hparams['lr_shed_gamma']) \n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
