{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_last_msg_id": "e70feb489ca54176a47d09a626ba9a30"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "import torch \n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import multiprocessing.dummy as mp\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.core import LightningModule\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers.tensorboard import TensorBoardLogger\n",
    "\n",
    "sys.path.append('../..')\n",
    "from lib.schedulers import DelayedScheduler\n",
    "from lib.datasets import (max_lbl_nums, actual_lbl_nums, \n",
    "                          patches_rgb_mean_av1, patches_rgb_std_av1, \n",
    "                          get_train_test_img_ids_split)\n",
    "from lib.dataloaders import PatchesDataset, WSIPatchesDatasetRaw\n",
    "from lib.augmentations import augment_v1_clr_only, augment_empty_clr_only\n",
    "from lib.losses import SmoothLoss\n",
    "\n",
    "from lib.models.unetv1 import get_model\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_last_msg_id": "c20f269b40b040879951d8b224421d7b"
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "# from lib.datasets import patches_csv_path, patches_path\n",
    "from lib.datasets import (patches_clean90_csv_path as patches_csv_path, patches_path,\n",
    "                          patches_clean90_pkl_path as patches_pkl_path)\n",
    "# from lib.dataloaders import imread, get_g_score_num, get_provider_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_last_msg_id": "2314285117bb4e0e8098def61f512327"
   },
   "outputs": [],
   "source": [
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "    \n",
    "def get_pretrained_model(get_model_fn, checkpoint, device):\n",
    "    tmp = torch.load(checkpoint, map_location=device)\n",
    "    \n",
    "    model = get_model_fn(actual_lbl_nums)\n",
    "\n",
    "    module = nn.Sequential()\n",
    "\n",
    "    module.add_module('model', model)\n",
    "\n",
    "    module.to(device);\n",
    "\n",
    "    module.load_state_dict(tmp['state_dict'])\n",
    "\n",
    "    model.segmentation = False\n",
    "    model.classification_head = None\n",
    "    model.autodecoder = None\n",
    "    module.eval();\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_features(imgs, features_batch_size=512):\n",
    "    model.eval()\n",
    "    \n",
    "    imgs = imgs if isinstance(imgs, torch.Tensor) else torch.from_numpy(imgs)\n",
    "    imgs = imgs.to(patches_device)\n",
    "    n_imgs = (imgs - rgb_mean) / rgb_std\n",
    "    \n",
    "    b_features = []\n",
    "    for b in range(0, n_imgs.shape[0], features_batch_size):\n",
    "        with torch.no_grad():\n",
    "            features, *_ = model(n_imgs[b:b+features_batch_size], return_features=True)\n",
    "            b_features.append(features)\n",
    "\n",
    "    features = torch.cat(b_features, dim=0)\n",
    "    \n",
    "    return features.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_last_msg_id": "f04bdf8a6bc54f19843e5ceef15e5f7a"
   },
   "outputs": [],
   "source": [
    "patches_device = torch.device('cuda:0')\n",
    "# patches_device = torch.device('cpu')\n",
    "main_device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_last_msg_id": "d107040375294da89b672ca4ab7672d7"
   },
   "outputs": [],
   "source": [
    "model = get_pretrained_model(get_model, \"../Patches256TestRun/version_0/checkpoints/last.ckpt\", patches_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_last_msg_id": "f69f582aabf040b1a212671a064ce362"
   },
   "outputs": [],
   "source": [
    "# model = torch.jit.script(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_last_msg_id": "cb6b9f7120ed47c5890cba43e2c738b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function segmentation_models_pytorch.base.model.SegmentationModel.forward(self, x)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__class__.forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_last_msg_id": "7f1ab7b365194e6196bc8d1928b7394b"
   },
   "outputs": [],
   "source": [
    "rgb_mean, rgb_std = (torch.tensor(patches_rgb_mean_av1, dtype=torch.float32, device=patches_device), \n",
    "                     torch.tensor(patches_rgb_std_av1, dtype=torch.float32, device=patches_device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_last_msg_id": "9e019abd2f6f4df08264e7d161e300e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e8baa3bb9dcfb9cef5ca599d62bb8046',\n",
       " '9b2948ff81b64677a1a152a1532c1a50',\n",
       " '5b003d43ec0ce5979062442486f84cf7',\n",
       " '375b2c9501320b35ceb638a3274812aa']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img_ids, test_img_ids = get_train_test_img_ids_split()\n",
    "\n",
    "test_img_ids[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_last_msg_id": "51d4a182003348e493029f9e6c15ad97"
   },
   "outputs": [],
   "source": [
    "dataset = WSIPatchesDatasetRaw(train_img_ids, patches_pkl_path, \n",
    "                               scale=0.5, transform=augment_v1_clr_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_last_msg_id": "9691f9194e3544db8ab2e9d47f072687"
   },
   "outputs": [],
   "source": [
    "process = psutil.Process(os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_last_msg_id": "742ff56bf9f6405185d4b6698bfbe602"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_last_msg_id": "06ef4ef2afb24b56895bb7d8dd3bf391",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(5):        \n",
    "    memory = []\n",
    "\n",
    "    main_batch_size = 64\n",
    "\n",
    "    max_len = 300\n",
    "\n",
    "    idxs = list(range(len(dataset)))\n",
    "    random.shuffle(idxs)\n",
    "\n",
    "    def process_item(idx):\n",
    "        item_data = dataset[idx]\n",
    "        return item_data\n",
    "\n",
    "    b_features = torch.zeros((main_batch_size, max_len, 512, 8, 8), dtype=torch.float32)\n",
    "    b_ys = torch.zeros((main_batch_size, max_len), dtype=torch.int64)\n",
    "    b_xs = torch.zeros((main_batch_size, max_len), dtype=torch.int64)\n",
    "    b_provider = torch.zeros((main_batch_size), dtype=torch.int64)\n",
    "    b_isup_grade = torch.zeros((main_batch_size), dtype=torch.int64)\n",
    "    b_gleason_score = torch.zeros((main_batch_size), dtype=torch.int64)\n",
    "\n",
    "    batch = [b_features, b_ys, b_xs, b_provider, \n",
    "             b_isup_grade, b_gleason_score]\n",
    "\n",
    "    def clean_batch():\n",
    "        for a in batch:\n",
    "            a.fill_(-1)\n",
    "\n",
    "    clean_batch()\n",
    "\n",
    "    c_iter = 0\n",
    "    with mp.Pool(processes=6) as pool:\n",
    "        for item_data in tqdm(pool.imap_unordered(process_item, idxs), total=len(dataset)):\n",
    "        # for item_data in pool.imap_unordered(process_item, idxs):\n",
    "            imgs, ys, xs, provider, isup_grade, gleason_score = item_data\n",
    "            # imgs = torch.from_numpy(imgs).to(patches_device)\n",
    "            features = get_features(imgs)\n",
    "\n",
    "            b_iter = c_iter % main_batch_size\n",
    "            p = ys.shape[0]\n",
    "\n",
    "            b_features[b_iter, :p] = features[:max_len]\n",
    "            b_ys[b_iter, :p] = torch.from_numpy(ys)[:max_len]        \n",
    "            b_xs[b_iter, :p] = torch.from_numpy(xs)[:max_len]\n",
    "            b_provider[b_iter] = provider\n",
    "            b_isup_grade[b_iter] = isup_grade        \n",
    "            b_gleason_score[b_iter] = gleason_score\n",
    "\n",
    "            if (c_iter + 1) % main_batch_size == 0:\n",
    "                #process batch\n",
    "                #yield batch\n",
    "\n",
    "                # clean batch data\n",
    "                clean_batch()\n",
    "\n",
    "            c_iter += 1\n",
    "\n",
    "            memory.append(process.memory_info().rss)\n",
    "\n",
    "    plt.axes().ticklabel_format(style='sci', scilimits=(9, 9))\n",
    "    plt.plot(memory);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_last_msg_id": "7b61ee9e2180482698f253e0bf3938d1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_last_msg_id": "ffbdd625f4444173882f5b887d05ab39"
   },
   "outputs": [],
   "source": [
    "class WSIPatchesDataloader():\n",
    "    def __init__(self, dataset, batch_size=1, shuffle=False, num_workers=0, max_len=300):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_workers = num_workers\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.dataset) / self.batch_size)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.produce_batches()\n",
    "    \n",
    "    def produce_batches(self):\n",
    "        def process_item(idx):\n",
    "            item_data = self.dataset[idx]\n",
    "            return item_data\n",
    "\n",
    "        def clean_batch():\n",
    "            for a in batch:\n",
    "                a.fill_(-1)        \n",
    "        \n",
    "        idxs = list(range(len(self.dataset)))\n",
    "        \n",
    "        if self.shuffle:\n",
    "            random.shuffle(idxs)\n",
    "            \n",
    "        max_len = self.max_len\n",
    "\n",
    "        b_features = torch.zeros((main_batch_size, max_len, 512, 8, 8), dtype=torch.float32)\n",
    "        b_ys = torch.zeros((main_batch_size, max_len), dtype=torch.int64)\n",
    "        b_xs = torch.zeros((main_batch_size, max_len), dtype=torch.int64)\n",
    "        b_provider = torch.zeros((main_batch_size), dtype=torch.int64)\n",
    "        b_isup_grade = torch.zeros((main_batch_size), dtype=torch.int64)\n",
    "        b_gleason_score = torch.zeros((main_batch_size), dtype=torch.int64)\n",
    "\n",
    "        batch = [b_features, b_ys, b_xs, b_provider, \n",
    "                 b_isup_grade, b_gleason_score]\n",
    "\n",
    "        clean_batch()\n",
    "\n",
    "        c_iter = 0\n",
    "        with mp.Pool(processes=self.num_workers) as pool:\n",
    "            # for item_data in tqdm(pool.imap_unordered(process_item, idxs), total=len(dataset)):\n",
    "            for item_data in pool.imap_unordered(process_item, idxs):\n",
    "                imgs, ys, xs, provider, isup_grade, gleason_score = item_data\n",
    "                features = get_features(imgs)\n",
    "\n",
    "                b_iter = c_iter % main_batch_size\n",
    "                p = ys.shape[0]\n",
    "\n",
    "                b_features[b_iter, :p] = features[:max_len]\n",
    "                b_ys[b_iter, :p] = torch.from_numpy(ys)[:max_len]        \n",
    "                b_xs[b_iter, :p] = torch.from_numpy(xs)[:max_len]\n",
    "                b_provider[b_iter] = provider\n",
    "                b_provider[b_isup_grade] = isup_grade        \n",
    "                b_provider[b_gleason_score] = gleason_score\n",
    "\n",
    "                if (c_iter + 1) % main_batch_size == 0:\n",
    "                    #process batch\n",
    "                    yield batch\n",
    "\n",
    "                    # clean batch data\n",
    "                    clean_batch()\n",
    "\n",
    "                c_iter += 1\n",
    "\n",
    "        if c_iter % main_batch_size != 0:        \n",
    "            yield [a[:c_iter % main_batch_size] for a in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_last_msg_id": "718817e4aeaf40bdb2cfc2189ace72be"
   },
   "outputs": [],
   "source": [
    "main_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_last_msg_id": "95e32b299578459eb9f34f6d64362698"
   },
   "outputs": [],
   "source": [
    "train_loader = WSIPatchesDataloader(WSIPatchesDatasetRaw(train_img_ids, patches_pkl_path, \n",
    "                                                         scale=0.5, transform=augment_v1_clr_only), \n",
    "                                    main_batch_size, shuffle=True, num_workers=6, max_len=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_last_msg_id": "a181e7bd83da47038ea7942254c949cf"
   },
   "outputs": [],
   "source": [
    "memory = []\n",
    "for data in tqdm(train_loader, total=len(train_loader)):\n",
    "    memory.append(process.memory_info().rss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_last_msg_id": "78b697b7bb1e48af8e11fd64010712bf"
   },
   "outputs": [],
   "source": [
    "plt.axes().ticklabel_format(style='sci', scilimits=(9, 9))\n",
    "plt.plot(memory);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_last_msg_id": "c2ef5ab5033c499780613acb749ead59"
   },
   "outputs": [],
   "source": [
    "memory = []\n",
    "for data in tqdm(train_loader, total=len(train_loader)):\n",
    "    memory.append(process.memory_info().rss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_last_msg_id": "f77618d5778a40e3969ca3b42b551c6b"
   },
   "outputs": [],
   "source": [
    "plt.axes().ticklabel_format(style='sci', scilimits=(9, 9))\n",
    "plt.plot(memory);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_last_msg_id": "c906fa3aa6bb4d1f9ebf8f7329b8201e"
   },
   "outputs": [],
   "source": [
    "memory = []\n",
    "for data in tqdm(train_loader, total=len(train_loader)):\n",
    "    memory.append(process.memory_info().rss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_last_msg_id": "d808efc8876f4a8dafb0cc8fabbc8987"
   },
   "outputs": [],
   "source": [
    "plt.axes().ticklabel_format(style='sci', scilimits=(9, 9))\n",
    "plt.plot(memory);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_last_msg_id": "9ac92b45143d43d88aebb36fd34ea195"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_last_msg_id": "63d29ae88ed745d6adf2dd05991d03d0"
   },
   "outputs": [],
   "source": [
    "def get_batches():\n",
    "    main_batch_size = 64\n",
    "\n",
    "    max_len = 300\n",
    "\n",
    "    idxs = list(range(len(dataset)))\n",
    "    random.shuffle(idxs)\n",
    "\n",
    "    def process_item(idx):\n",
    "        item_data = dataset[idx]\n",
    "        return item_data\n",
    "\n",
    "    b_features = torch.zeros((main_batch_size, max_len, 512, 8, 8), dtype=torch.float32)\n",
    "    b_ys = torch.zeros((main_batch_size, max_len), dtype=torch.int64)\n",
    "    b_xs = torch.zeros((main_batch_size, max_len), dtype=torch.int64)\n",
    "    b_provider = torch.zeros((main_batch_size), dtype=torch.int64)\n",
    "    b_isup_grade = torch.zeros((main_batch_size), dtype=torch.int64)\n",
    "    b_gleason_score = torch.zeros((main_batch_size), dtype=torch.int64)\n",
    "\n",
    "    batch = [b_features, b_ys, b_xs, b_provider, \n",
    "             b_isup_grade, b_gleason_score]\n",
    "\n",
    "    def clean_batch():\n",
    "        for a in batch:\n",
    "            a.fill_(-1)\n",
    "\n",
    "    clean_batch()\n",
    "\n",
    "    c_iter = 0\n",
    "    with mp.Pool(processes=6) as pool:\n",
    "        # for item_data in tqdm(pool.imap_unordered(process_item, idxs), total=len(dataset)):\n",
    "        for item_data in pool.imap_unordered(process_item, idxs):\n",
    "            imgs, ys, xs, provider, isup_grade, gleason_score = item_data\n",
    "            imgs = torch.from_numpy(imgs).to(patches_device)\n",
    "            features = get_features(imgs)\n",
    "\n",
    "            b_iter = c_iter % main_batch_size\n",
    "            p = ys.shape[0]\n",
    "\n",
    "            b_features[b_iter, :p] = features[:max_len]\n",
    "            b_ys[b_iter, :p] = torch.from_numpy(ys)[:max_len]        \n",
    "            b_xs[b_iter, :p] = torch.from_numpy(xs)[:max_len]\n",
    "            b_provider[b_iter] = provider\n",
    "            b_provider[b_isup_grade] = isup_grade        \n",
    "            b_provider[b_gleason_score] = gleason_score\n",
    "\n",
    "            if (c_iter + 1) % main_batch_size == 0:\n",
    "                #process batch\n",
    "                yield batch\n",
    "\n",
    "                # clean batch data\n",
    "                clean_batch()\n",
    "\n",
    "            c_iter += 1\n",
    "\n",
    "    if c_iter % main_batch_size != 0:        \n",
    "        yield [a[:c_iter % main_batch_size] for a in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_last_msg_id": "ae9a7df88a61441d830923e5d76cb008"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd8a755d171747fc961926c81c11cfd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=132.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])\n",
      "tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])\n",
      "tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])\n",
      "tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])\n",
      "tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])\n",
      "tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])\n",
      "tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])\n",
      "tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])\n",
      "tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])\n",
      "tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])\n",
      "tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])\n",
      "tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])\n"
     ]
    }
   ],
   "source": [
    "memory = []\n",
    "for data in tqdm(get_batches(), total=132):\n",
    "    memory.append(process.memory_info().rss)\n",
    "    features, ys, xs, provider, isup_grade, gleason_score = data \n",
    "    print(isup_grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_last_msg_id": "3ca2919e427848d7909a390910be2d15"
   },
   "outputs": [],
   "source": [
    "plt.axes().ticklabel_format(style='sci', scilimits=(9, 9))\n",
    "plt.plot(memory);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
