{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_last_msg_id": "828908b48cc249dc8d7e0176d900006d"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "import torch \n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.core import LightningModule\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers.tensorboard import TensorBoardLogger\n",
    "\n",
    "sys.path.append('../..')\n",
    "from lib.schedulers import DelayedScheduler\n",
    "from lib.datasets import (max_lbl_nums, actual_lbl_nums, \n",
    "                          patches_rgb_mean_av1, patches_rgb_std_av1, \n",
    "                          get_train_test_img_ids_split)\n",
    "from lib.dataloaders import PatchesDataset, WSIPatchesDatasetRaw\n",
    "from lib.augmentations import augment_v1_clr_only, augment_empty_clr_only\n",
    "from lib.losses import SmoothLoss\n",
    "\n",
    "from lib.models.unetv1 import get_model\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_last_msg_id": "09d52ecf3dcf4e108d7eb058907a363e"
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "# from lib.datasets import patches_csv_path, patches_path\n",
    "from lib.datasets import (patches_clean90_csv_path as patches_csv_path, patches_path,\n",
    "                          patches_clean90_pkl_path as patches_pkl_path)\n",
    "# from lib.dataloaders import imread, get_g_score_num, get_provider_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_last_msg_id": "8ab96719a1884dbd88040c78a8f910ad"
   },
   "outputs": [],
   "source": [
    "train_img_ids, test_img_ids = get_train_test_img_ids_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_last_msg_id": "c3ac8bfff4e74d4b8bb506c206a370b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8420"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_img_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_last_msg_id": "e23e16c2a30d470d857e13308b4d3228"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e8baa3bb9dcfb9cef5ca599d62bb8046',\n",
       " '9b2948ff81b64677a1a152a1532c1a50',\n",
       " '5b003d43ec0ce5979062442486f84cf7',\n",
       " '375b2c9501320b35ceb638a3274812aa']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img_ids[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_last_msg_id": "9a0bb7812fc146d2b42e8be25cee91d4"
   },
   "outputs": [],
   "source": [
    "class WSIPatchesDataset1D(WSIPatchesDatasetRaw):\n",
    "    def __init__(self, image_ids, csv_path=patches_csv_path,\n",
    "                 path=patches_path, scale=1, transform=None, max_len=300):\n",
    "        super().__init__(image_ids, csv_path, patches_path, scale, transform)\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        def trim(x):\n",
    "            return x[:self.max_len]\n",
    "        \n",
    "        def pad(x):\n",
    "            return np.pad(x[:self.max_len], ((0, self.max_len-p),)+((0, 0),)*(len(x.shape)-1), constant_values=-1)\n",
    "        \n",
    "        imgs, ys, xs, provider, isup_grade, gleason_score =\\\n",
    "            super().__getitem__(idx)\n",
    "        \n",
    "        p = imgs.shape[0]\n",
    "        if p > self.max_len:\n",
    "            imgs, ys, xs = trim(imgs), trim(ys), trim(xs)\n",
    "        elif p < self.max_len:\n",
    "            imgs, ys, xs = pad(imgs), pad(ys), pad(xs)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        return imgs, ys, xs, provider, isup_grade, gleason_score\n",
    "    \n",
    "    \n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_last_msg_id": "8e986ca68bbe473b8d127710e870284d"
   },
   "outputs": [],
   "source": [
    "max_len = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_last_msg_id": "a4b519577f2f4020b28b9868381d56c0"
   },
   "outputs": [],
   "source": [
    "rgb_mean, rgb_std = (torch.tensor(patches_rgb_mean_av1, dtype=torch.float32), \n",
    "                     torch.tensor(patches_rgb_std_av1, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_last_msg_id": "dd71d323356b428b85b93ec345281e0e"
   },
   "outputs": [],
   "source": [
    "# imgs, ys, xs, provider, isup_grade, gleason_score = next(iter(train_wsipatches_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_last_msg_id": "af9a0f6e1af849149226ea93e8cab492"
   },
   "outputs": [],
   "source": [
    "patches_device = torch.device('cuda:0')\n",
    "# patches_device = torch.device('cpu')\n",
    "main_device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_last_msg_id": "772acbd8039749ad819d1b334549b69b"
   },
   "outputs": [],
   "source": [
    "tmp = torch.load(\"../Patches256TestRun/version_0/checkpoints/last.ckpt\", map_location=patches_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_last_msg_id": "093e26727ca848eaafc051fd265b9e48"
   },
   "outputs": [],
   "source": [
    "# model = get_model(actual_lbl_nums, decoder=False, labels=False)\n",
    "model = get_model(actual_lbl_nums)\n",
    "\n",
    "module = nn.Sequential()\n",
    "\n",
    "module.add_module('model', model)\n",
    "\n",
    "module.to(patches_device);\n",
    "\n",
    "module.load_state_dict(tmp['state_dict'])\n",
    "\n",
    "model.segmentation = False\n",
    "model.classification_head = None\n",
    "model.autodecoder = None\n",
    "module.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_last_msg_id": "6545690ff61b48ca88ba5c4413bd0182"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_last_msg_id": "ca98ad1573c54cc28a818cd3c900e188"
   },
   "outputs": [],
   "source": [
    "rgb_mean = rgb_mean.to(patches_device)\n",
    "rgb_std = rgb_std.to(patches_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_last_msg_id": "ba5bb77a160843eda0e23f233f3abc5b"
   },
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_last_msg_id": "743f214533aa46b781a97073184744ac"
   },
   "outputs": [],
   "source": [
    "features_batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_last_msg_id": "c25c0dcb38884f578892132c59e9f91a"
   },
   "outputs": [],
   "source": [
    "def get_features(imgs):\n",
    "    imgs = imgs.to(patches_device)\n",
    "    n_imgs = (imgs - rgb_mean) / rgb_std\n",
    "    \n",
    "    b_features = []\n",
    "    for b in range(0, n_imgs.shape[0], features_batch_size):\n",
    "        with torch.no_grad():\n",
    "            features, *_ = model(n_imgs[b:b+features_batch_size], return_features=True)\n",
    "            b_features.append(features)\n",
    "\n",
    "    features = torch.cat(b_features, dim=0)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_last_msg_id": "03e99894ebab4ae1a304be5541d35f8a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_last_msg_id": "a0be98309fe0476ca8134d32020e4f47"
   },
   "outputs": [],
   "source": [
    "# model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_last_msg_id": "ba97756f99eb44ad8db0c599139e783c"
   },
   "outputs": [],
   "source": [
    "#train_loader = MainBatchGenerator1D(train_img_ids, batch_size=32, patches_batch_size=2, shuffle=True, \n",
    "#                                    num_workers=6, max_len=300, patches_csv_path=patches_csv_path,\n",
    "#                                    scale=0.5, transform=augment_empty_clr_only)\n",
    "#                                    # scale=0.5, transform=augment_v1_clr_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_last_msg_id": "32726e48ae7b4a368cc3c1cbbd74c745"
   },
   "outputs": [],
   "source": [
    "train_wsipatches_dataset = WSIPatchesDatasetRaw(train_img_ids, patches_pkl_path, \n",
    "                                                scale=0.5, transform=augment_v1_clr_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_last_msg_id": "88435b24b6e846d982d97390b21a47be"
   },
   "outputs": [],
   "source": [
    "#for features, target in tqdm(train_loader, total=len(train_loader)):\n",
    "#    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_last_msg_id": "d49a1a41bccb45dcbc396f01ad86e333"
   },
   "outputs": [],
   "source": [
    "# from multiprocessing import Pool\n",
    "import multiprocessing.dummy as mp\n",
    "# import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_last_msg_id": "3e3a9ae9c68d4fa68fb48b7a31c66cbb"
   },
   "outputs": [],
   "source": [
    "#mp.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_last_msg_id": "5580c8ae9c19452c9da00121e95aa1c7"
   },
   "outputs": [],
   "source": [
    "# multiprocessing.dummy, processes=6, imgs = torch.from_numpy(imgs).to(patches_device) ~ 19 минут\n",
    "\n",
    "import multiprocessing.dummy as mp\n",
    "\n",
    "idxs = list(range(len(train_wsipatches_dataset)))\n",
    "\n",
    "def process_item(idx):\n",
    "    item_data = train_wsipatches_dataset[idx]\n",
    "    return np.array([1.0, 2.0], dtype=np.float32), 500 #item_data\n",
    "\n",
    "with mp.Pool(processes=6) as pool:\n",
    "    for item_data in tqdm(pool.imap_unordered(process_item, idxs), total=len(idxs)):\n",
    "        imgs, *_ = item_data\n",
    "            \n",
    "        imgs = torch.tensor(imgs)\n",
    "        #imgs = torch.from_numpy(imgs) #.half()\n",
    "        #imgs = torch.from_numpy(imgs).to(patches_device)\n",
    "        #featurtes = get_features(imgs).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "_last_msg_id": "994c8aebfbd9457182b56ad0b24452bd"
   },
   "outputs": [],
   "source": [
    "a = np.random.random((200, 3, 256, 256)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "_last_msg_id": "d232920aa74148e4874f0c26d498c76b"
   },
   "outputs": [],
   "source": [
    "at = torch.tensor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "_last_msg_id": "bff8e6694ef541c383a2f6b37d716791"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 149 ms, sys: 61 µs, total: 149 ms\n",
      "Wall time: 148 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _ in range(10):\n",
    "    # b = torch.from_numpy(a).to(patches_device)\n",
    "    # b = torch.tensor(a, device=patches_device)\n",
    "    b = torch.zeros_like(b)\n",
    "    b[...] = at[...]\n",
    "    b.sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = list(range(len(train_wsipatches_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_last_msg_id": "c3d845a4e2b74d14be9566299df200ae"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f01f4c78e249eabc37d149bd7d58ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8420.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-3:\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-6:\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-24-0ded585516ed>\", line 2, in process_item\n",
      "    item_data = train_wsipatches_dataset[idx]\n",
      "  File \"../../lib/dataloaders.py\", line 133, in __getitem__\n",
      "    imgs = self.transform(imgs)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../../lib/augmentations.py\", line 90, in augment_v1_clr_only\n",
      "    return _augment_clr_only(imgs, _aug_v1_clr_only)\n",
      "  File \"../../lib/augmentations.py\", line 76, in _augment_clr_only\n",
      "    imgs = aug(**imgs)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/core/composition.py\", line 176, in __call__\n",
      "    data = t(force_apply=force_apply, **data)\n",
      "Process ForkPoolWorker-1:\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-24-0ded585516ed>\", line 2, in process_item\n",
      "    item_data = train_wsipatches_dataset[idx]\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/core/composition.py\", line 221, in __call__\n",
      "    data = t(force_apply=True, **data)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/core/transforms_interface.py\", line 87, in __call__\n",
      "    return self.apply_with_params(params, **kwargs)\n",
      "  File \"../../lib/dataloaders.py\", line 126, in __getitem__\n",
      "    scaling_factor=(1, 2))[..., ::-1]\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-24-0ded585516ed>\", line 2, in process_item\n",
      "    item_data = train_wsipatches_dataset[idx]\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-24-0ded585516ed>\", line 2, in process_item\n",
      "    item_data = train_wsipatches_dataset[idx]\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/turbojpeg.py\", line 256, in decode\n",
      "    0, scaled_height, pixel_format, flags)\n",
      "KeyboardInterrupt\n",
      "  File \"../../lib/dataloaders.py\", line 133, in __getitem__\n",
      "    imgs = self.transform(imgs)\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-24-0ded585516ed>\", line 2, in process_item\n",
      "    item_data = train_wsipatches_dataset[idx]\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"../../lib/dataloaders.py\", line 133, in __getitem__\n",
      "    imgs = self.transform(imgs)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/core/transforms_interface.py\", line 100, in apply_with_params\n",
      "    res[key] = target_function(arg, **dict(params, **target_dependencies))\n",
      "  File \"../../lib/dataloaders.py\", line 133, in __getitem__\n",
      "    imgs = self.transform(imgs)\n",
      "  File \"../../lib/augmentations.py\", line 90, in augment_v1_clr_only\n",
      "    return _augment_clr_only(imgs, _aug_v1_clr_only)\n",
      "  File \"../../lib/augmentations.py\", line 76, in _augment_clr_only\n",
      "    imgs = aug(**imgs)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../../lib/augmentations.py\", line 90, in augment_v1_clr_only\n",
      "    return _augment_clr_only(imgs, _aug_v1_clr_only)\n",
      "  File \"../../lib/augmentations.py\", line 76, in _augment_clr_only\n",
      "    imgs = aug(**imgs)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/augmentations/transforms.py\", line 2456, in apply\n",
      "    return F.median_blur(image, ksize)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 127, in worker\n",
      "    put((job, i, result))\n",
      "  File \"../../lib/augmentations.py\", line 90, in augment_v1_clr_only\n",
      "    return _augment_clr_only(imgs, _aug_v1_clr_only)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/core/composition.py\", line 176, in __call__\n",
      "    data = t(force_apply=force_apply, **data)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 358, in put\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"../../lib/augmentations.py\", line 76, in _augment_clr_only\n",
      "    imgs = aug(**imgs)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/core/composition.py\", line 221, in __call__\n",
      "    data = t(force_apply=True, **data)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/augmentations/functional.py\", line 54, in wrapped_function\n",
      "    result = func(img, *args, **kwargs)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/core/composition.py\", line 176, in __call__\n",
      "    data = t(force_apply=force_apply, **data)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/core/transforms_interface.py\", line 87, in __call__\n",
      "    return self.apply_with_params(params, **kwargs)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/core/transforms_interface.py\", line 100, in apply_with_params\n",
      "    res[key] = target_function(arg, **dict(params, **target_dependencies))\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/core/composition.py\", line 176, in __call__\n",
      "    data = t(force_apply=force_apply, **data)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/core/composition.py\", line 221, in __call__\n",
      "    data = t(force_apply=True, **data)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/imgaug/transforms.py\", line 38, in __call__\n",
      "    return super(BasicIAATransform, self).__call__(**kwargs)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/core/transforms_interface.py\", line 87, in __call__\n",
      "    return self.apply_with_params(params, **kwargs)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/core/transforms_interface.py\", line 100, in apply_with_params\n",
      "    res[key] = target_function(arg, **dict(params, **target_dependencies))\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/augmentations/transforms.py\", line 2314, in apply\n",
      "    return F.brightness_contrast_adjust(img, alpha, beta, self.brightness_by_max)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/imgaug/transforms.py\", line 46, in apply\n",
      "    return deterministic_processor.augment_image(img)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/imgaug/augmenters/meta.py\", line 323, in augment_image\n",
      "    return self.augment_images([image], hooks=hooks)[0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/imgaug/augmenters/meta.py\", line 431, in augment_images\n",
      "    hooks=hooks\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/imgaug/augmenters/arithmetic.py\", line 242, in _augment_images\n",
      "    samples = np.tile(samples, (1, 1, nb_channels))\n",
      "  File \"<__array_function__ internals>\", line 6, in tile\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/numpy/lib/shape_base.py\", line 1242, in tile\n",
      "    c = c.reshape(-1, n).repeat(nrep, 0)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\", line 333, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/augmentations/functional.py\", line 723, in median_blur\n",
      "    return blur_fn(img)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/core/transforms_interface.py\", line 87, in __call__\n",
      "    return self.apply_with_params(params, **kwargs)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/augmentations/functional.py\", line 1311, in brightness_contrast_adjust\n",
      "    return _brightness_contrast_adjust_uint(img, alpha, beta, beta_by_max)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/augmentations/functional.py\", line 180, in __process_fn\n",
      "    img = process_fn(img, **kwargs)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/augmentations/functional.py\", line 54, in wrapped_function\n",
      "    result = func(img, *args, **kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/core/transforms_interface.py\", line 100, in apply_with_params\n",
      "    res[key] = target_function(arg, **dict(params, **target_dependencies))\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/augmentations/functional.py\", line 1305, in _brightness_contrast_adjust_uint\n",
      "    img = cv2.LUT(img, lut)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/augmentations/transforms.py\", line 2456, in apply\n",
      "    return F.median_blur(image, ksize)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/augmentations/functional.py\", line 54, in wrapped_function\n",
      "    result = func(img, *args, **kwargs)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/augmentations/functional.py\", line 723, in median_blur\n",
      "    return blur_fn(img)\n",
      "  File \"/home/ruslan/anaconda3/lib/python3.7/site-packages/albumentations/augmentations/functional.py\", line 180, in __process_fn\n",
      "    img = process_fn(img, **kwargs)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-0ded585516ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# imgs = torch.from_numpy(imgs).to(patches_device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mfeaturtes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def process_item(idx):\n",
    "    item_data = train_wsipatches_dataset[idx]\n",
    "    imgs, *_ = item_data\n",
    "    imgs = torch.tensor(imgs)\n",
    "    return imgs\n",
    "\n",
    "new_rows = []\n",
    "with mp.Pool(processes=6) as pool:\n",
    "    for item_data in tqdm(pool.imap_unordered(process_item, idxs), total=len(idxs)):\n",
    "        # imgs, *_ = item_data\n",
    "        \n",
    "        # imgs = torch.from_numpy(imgs).to(patches_device)\n",
    "        imgs = item_data\n",
    "        featurtes = get_features(imgs.to(patches_device)).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_last_msg_id": "b9d15d1a41cc45098c87e93ebaeae6cf"
   },
   "outputs": [],
   "source": [
    "# multiprocessing.dummy, processes=6, imgs = torch.from_numpy(imgs).to(patches_device) ~ 19 минут\n",
    "\n",
    "from multiprocessing.dummy import Pool\n",
    "\n",
    "idxs = list(range(len(train_wsipatches_dataset)))\n",
    "\n",
    "def process_item(idx):\n",
    "    item_data = train_wsipatches_dataset[idx]\n",
    "    return item_data\n",
    "\n",
    "with Pool(processes=6) as pool:\n",
    "    for item_data in tqdm(pool.imap_unordered(process_item, idxs), total=len(idxs)):\n",
    "        imgs, *_ = item_data\n",
    "            \n",
    "        imgs = torch.from_numpy(imgs).to(patches_device)\n",
    "        featurtes = get_features(imgs).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_last_msg_id": "8082c446336b4bd88e1da24b0e99d903"
   },
   "outputs": [],
   "source": [
    "#for imgs, *_ in tqdm(train_wsipatches_dataset, total=len(train_wsipatches_dataset)):\n",
    "#    imgs = torch.from_numpy(imgs).to(patches_device)\n",
    "#    # imgs = torch.tensor(imgs) # .to(patches_device)\n",
    "#    featurtes = get_features(imgs).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_last_msg_id": "4ee2e86a8bf04a4095b7c71e2bd0efcf"
   },
   "outputs": [],
   "source": [
    "#imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_last_msg_id": "1336382ef82948968ffe8436bb8f468e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
