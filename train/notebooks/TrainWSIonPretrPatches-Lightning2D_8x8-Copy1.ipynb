{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_last_msg_id": "492cdd8720b642e180271fbbb2264f21"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_last_msg_id": "fb180258aa6a402299cfc254f394a56c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import psutil\n",
    "\n",
    "import random\n",
    "import math\n",
    "from functools import partial\n",
    "\n",
    "import torch \n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import multiprocessing.dummy as mp\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.core import LightningModule\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers.tensorboard import TensorBoardLogger\n",
    "\n",
    "\n",
    "from lib.schedulers import DelayedScheduler\n",
    "from lib.datasets import (max_lbl_nums, actual_lbl_nums, \n",
    "                          patches_rgb_mean_av1, patches_rgb_std_av1, \n",
    "                          get_train_test_img_ids_split)\n",
    "from lib.dataloaders import PatchesDataset, WSIPatchesDatasetRaw, WSIPatchesDummyDataloader\n",
    "from lib.augmentations import augment_v1_clr_only, augment_empty_clr_only\n",
    "from lib.losses import SmoothLoss\n",
    "from lib.trainers import WSIModuleV1\n",
    "\n",
    "from lib.models.unetv1 import get_model\n",
    "from lib.models.features_map import FeaturesMap\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_last_msg_id": "8b898fbf92cd415281a121c96bbe113e"
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "# from lib.datasets import patches_csv_path, patches_path\n",
    "from lib.datasets import (patches_clean90_csv_path as patches_csv_path, patches_path,\n",
    "                          patches_clean90_pkl_path as patches_pkl_path)\n",
    "# from lib.dataloaders import imread, get_g_score_num, get_provider_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_last_msg_id": "d7c19a1b372a48bb804be2dec6010e47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e8baa3bb9dcfb9cef5ca599d62bb8046',\n",
       " '9b2948ff81b64677a1a152a1532c1a50',\n",
       " '5b003d43ec0ce5979062442486f84cf7',\n",
       " '375b2c9501320b35ceb638a3274812aa']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img_ids, test_img_ids = get_train_test_img_ids_split()\n",
    "\n",
    "test_img_ids[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_last_msg_id": "da6f30ad39b947648ac3ea851acbf463"
   },
   "outputs": [],
   "source": [
    "from lib.dataloaders import WSIPatchesDataloader, WSIPatchesDatasetRaw\n",
    "from lib.utils import get_pretrained_model, get_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_last_msg_id": "e43a2c4a58304c738a112e9ea91c651d"
   },
   "outputs": [],
   "source": [
    "main_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_last_msg_id": "c0598ac7f1ac4555b6054ef3cdaf4030"
   },
   "outputs": [],
   "source": [
    "train_batch_path = '/mnt/HDDData/pdata/processed/pretrained_64x8x8/train/{}/'\n",
    "test_batch_path = '/mnt/HDDData/pdata/processed/pretrained_64x8x8/val/'\n",
    "\n",
    "train_loader = WSIPatchesDummyDataloader(train_batch_path, precalc_epochs=32, shuffle=True)\n",
    "val_loader = WSIPatchesDummyDataloader(test_batch_path, precalc_epochs=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_last_msg_id": "e7a8e703fc73493094843d7b71726242"
   },
   "outputs": [],
   "source": [
    "steps_in_epoh = 1\n",
    "\n",
    "epochs = 90\n",
    "\n",
    "warmup_epochs = 0\n",
    "warmup_steps = 0\n",
    "batch_size = 64\n",
    "\n",
    "hparams = {\n",
    "    'module': {\n",
    "        'name': 'lib.trainers.WSIModuleV1',\n",
    "        'params': {\n",
    "            'model': {\n",
    "                'name': 'lib.models.wsi_resnets.Resnet_512x1x1',\n",
    "                'params': {\n",
    "                    'backbone': 'resnet18',\n",
    "                    'backbone_features': 512,\n",
    "                    'classes': max_lbl_nums,\n",
    "                    'features_do': 0,\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    'batch_size': batch_size,\n",
    "    'learning_rate': 0.001 * batch_size / 256,\n",
    "    'dataset': {\n",
    "        'dataloader': 'dummy',\n",
    "        'rgb_mean': patches_rgb_mean_av1,\n",
    "        'rgb_std': patches_rgb_std_av1,\n",
    "        'classes': max_lbl_nums,\n",
    "        'precalc_epochs': 50,\n",
    "        'train_test_split': {},\n",
    "    },\n",
    "    'optimizer': {\n",
    "        'name': 'torch.optim.Adam',\n",
    "        'params': {\n",
    "            'weight_decay': 1e-4\n",
    "        }\n",
    "    },\n",
    "    'scheduler': {\n",
    "        'name': 'lib.schedulers.ExponentialLRWithMin',\n",
    "        'params': {\n",
    "            'gamma': 0.92,\n",
    "            'eta_min': 1.25e-5\n",
    "        },\n",
    "        'interval': 'epoch'\n",
    "    },\n",
    "    'loss': {\n",
    "        'weights': {\n",
    "            'reg': 1 / 2,\n",
    "            'class': 9 / 2\n",
    "        },\n",
    "        'label_smoothing': 0.1\n",
    "    },\n",
    "    'warmup_steps': warmup_steps,\n",
    "    'steps_in_epoh': steps_in_epoh,\n",
    "    'epochs': epochs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_last_msg_id": "39335c94569847738c5d248d708519f7"
   },
   "outputs": [],
   "source": [
    "steps_in_epoh = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_last_msg_id": "1563844016724f419f294b6e23adb139"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_in_epoh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_last_msg_id": "02ee8587fa0e4fdb8e91c0e95d42af32"
   },
   "outputs": [],
   "source": [
    "hparams['steps_in_batch'] = steps_in_epoh\n",
    "if 'T_max' in hparams['scheduler']['params']:\n",
    "    hparams['scheduler']['params']['T_max'] = (epochs * steps_in_epoh -\n",
    "                                               warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_last_msg_id": "cda1fef080d146e18db4cb66a5dd65a5"
   },
   "outputs": [],
   "source": [
    "# tmp[0].shape\n",
    "# torch.Size([64, 300, 64, 8, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_last_msg_id": "932b909d6aaf418a9fb4654d5f36eeee"
   },
   "outputs": [],
   "source": [
    "class FeaturesMap(nn.Module):\n",
    "    def __init__(self, use_dummy_feature, f_channels=512, max_height=70,\n",
    "                 max_width=40, f_size=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.f_size = f_size\n",
    "        self.max_height = max_height * self.f_size\n",
    "        self.max_width = max_width * self.f_size\n",
    "        self.f_channels = f_channels\n",
    "        self.use_dummy_feature = use_dummy_feature\n",
    "        \n",
    "        if self.use_dummy_feature:\n",
    "            self.backend_feature =\\\n",
    "                nn.Parameter(torch.full((self.f_channels, 1, 1), 0))\n",
    "\n",
    "    def forward(self, features, ys, xs, validation=None):\n",
    "        if validation is None:\n",
    "            validation = not self.training\n",
    "\n",
    "        b_sz = features.shape[0]\n",
    "\n",
    "        if self.use_dummy_feature:\n",
    "            f_map = self.backend_feature.expand(self.f_channels,\n",
    "                                                self.max_height,\n",
    "                                                self.max_width)\n",
    "        else:\n",
    "            f_map = torch.full((self.f_channels, self.max_height,\n",
    "                                self.max_width), 0,\n",
    "                               dtype=features.dtype, device=features.device)\n",
    "\n",
    "        res_f_maps = []\n",
    "        for b in range(b_sz):\n",
    "            real_mask = ys[b] > -1\n",
    "\n",
    "            min_y, max_y = (ys[b, real_mask].min().item(),\n",
    "                            ys[b, real_mask].max().item())\n",
    "            min_x, max_x = (xs[b, real_mask].min().item(),\n",
    "                            xs[b, real_mask].max().item())\n",
    "            \n",
    "            height = (max_y - min_y + 1) * self.f_size\n",
    "            width = (max_x - min_x + 1) * self.f_size\n",
    "\n",
    "            tmp_f_map = torch.full((self.f_channels, height, width), -1,\n",
    "                                   dtype=features.dtype,\n",
    "                                   device=features.device)\n",
    "\n",
    "            if self.f_size == 1:\n",
    "                tmp_f_map[:, ys[b, real_mask] - min_y, xs[b, real_mask] - min_x] =\\\n",
    "                    features[b, :, real_mask]\n",
    "            else:\n",
    "                for n in range(real_mask.sum().item()):\n",
    "                    t = features[b, n]\n",
    "                    _y = ys[b, n] - min_y\n",
    "                    _x = xs[b, n] - min_x                    \n",
    "                    tmp_f_map[:, _y*self.f_size:(_y+1)*self.f_size, \n",
    "                                 _x*self.f_size:(_x+1)*self.f_size] = t\n",
    "\n",
    "            if width > height:\n",
    "                tmp_f_map = tmp_f_map.transpose(-1, -2)\n",
    "\n",
    "            _, height, width = tmp_f_map.shape\n",
    "            # print(height, width)\n",
    "\n",
    "            h_dif = height - self.max_height\n",
    "            w_dif = width - self.max_width\n",
    "\n",
    "            if h_dif > 0:\n",
    "                cut_top = (math.ceil(h_dif / 2) if validation else\n",
    "                           random.randint(0, h_dif))\n",
    "                cut_bottom = -(h_dif - cut_top)\n",
    "                if cut_bottom >= 0:\n",
    "                    cut_bottom = None\n",
    "                pad_top, pad_bottom = 0, 0\n",
    "            else:\n",
    "                pad_top = (math.ceil(-h_dif / 2) if validation else\n",
    "                           random.randint(0, -h_dif))\n",
    "                pad_bottom = -h_dif - pad_top\n",
    "                cut_top, cut_bottom = 0, None\n",
    "\n",
    "            if w_dif > 0:\n",
    "                cut_left = (math.ceil(w_dif / 2) if validation else\n",
    "                            random.randint(0, w_dif))\n",
    "                cut_right = -(w_dif - cut_left)\n",
    "                if cut_right >= 0:\n",
    "                    cut_right = None\n",
    "                pad_right, pad_left = 0, 0\n",
    "            else:\n",
    "                pad_right = (math.ceil(-w_dif / 2) if validation else\n",
    "                             random.randint(0, -w_dif))\n",
    "                pad_left = -w_dif - pad_right\n",
    "                cut_left, cut_right = 0, None\n",
    "\n",
    "            if not validation:\n",
    "                if random.random() > 0.5:\n",
    "                    tmp_f_map = torch.flip(tmp_f_map, [-1])\n",
    "\n",
    "                if random.random() > 0.5:\n",
    "                    tmp_f_map = torch.flip(tmp_f_map, [-2])\n",
    "\n",
    "            tmp_f_map = F.pad(tmp_f_map[:, cut_top:cut_bottom,\n",
    "                                        cut_left:cut_right],\n",
    "                              (pad_right, pad_left,\n",
    "                               pad_top, pad_bottom), value=-1)\n",
    "\n",
    "            real_2d_mask = (tmp_f_map != -1).all(dim=0)\n",
    "\n",
    "            # print(real_2d_mask.shape, f_map.shape, tmp_f_map.shape)\n",
    "\n",
    "            res_f_map = (~real_2d_mask) * f_map + real_2d_mask * tmp_f_map\n",
    "            res_f_maps.append(res_f_map)\n",
    "\n",
    "        return torch.stack(res_f_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_last_msg_id": "880f5908920b4fec84a4a405d21975d4"
   },
   "outputs": [],
   "source": [
    "features, ys, xs, provider, isup_grade, gleason_score = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_last_msg_id": "11779cf938f4478c825cfed755cae335"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 300, 64, 8, 8])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_last_msg_id": "00f1bbf55bd54b45889619fc2c06eabd"
   },
   "outputs": [],
   "source": [
    "# f_map = FeaturesMap(False, 64, 70, 40, f_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_last_msg_id": "2325b9f8fdbc4ad3836e0785a42e5623"
   },
   "outputs": [],
   "source": [
    "self = lambda x: x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_last_msg_id": "ac65b5278c47492686345d6e81cc5a84"
   },
   "outputs": [],
   "source": [
    "self.t_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_last_msg_id": "e607a71b26524204ba5b2deffc2fdd6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.2 s, sys: 123 ms, total: 22.3 s\n",
      "Wall time: 22.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "s_features = []\n",
    "all_cnt = (ys > -1).sum()*self.t_size*self.t_size\n",
    "# all_cnt = (ys[:2] > -1).sum()*self.t_size*self.t_size\n",
    "s_coords = torch.zeros((all_cnt, 3), dtype=torch.int32)\n",
    "cnt = 0\n",
    "for b in range(ys.shape[0]):\n",
    "# for b in range(2):\n",
    "    y_min = ys[b].min()\n",
    "    x_min = xs[b].min()    \n",
    "    for n in range(ys.shape[1]):\n",
    "        if ys[b, n] > -1:\n",
    "            for p_y in range(self.t_size):\n",
    "                for p_x in range(self.t_size):  \n",
    "                    s_coords[cnt, 0] = b\n",
    "                    s_coords[cnt, 1] = (ys[b, n]-y_min)*self.t_size + p_y\n",
    "                    s_coords[cnt, 2] = (xs[b, n]-x_min)*self.t_size + p_x\n",
    "                    s_features.append(features[b, n, :, p_y, p_x])\n",
    "                    cnt += 1\n",
    "                    \n",
    "s_features = torch.stack(s_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_last_msg_id": "08c7c8d5759a46fd82f9a1d7362a494b"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_last_msg_id": "bf3c3466ec0847508918f3535b99c169"
   },
   "outputs": [],
   "source": [
    "# features, ys, xs = features.to(device), ys.to(device), xs.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_last_msg_id": "2219f183a46d48438023af0d61073b9f"
   },
   "outputs": [],
   "source": [
    "s_features, s_coords = s_features.to(device), s_coords.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_last_msg_id": "3be4e5cc0e5f4ae692d9f9c0e906d569"
   },
   "outputs": [],
   "source": [
    "import spconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_last_msg_id": "ae176a36c21e4fdb8cac49b87aecb61d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(599, device='cuda:0', dtype=torch.int32),\n",
       " tensor(495, device='cuda:0', dtype=torch.int32))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_coords[:, 1].max(), s_coords[:, 2].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_last_msg_id": "22ac634e0f3d48fd8a080a0ee0c26bc7"
   },
   "outputs": [],
   "source": [
    "spatial_shape = (640, 640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_last_msg_id": "80d4c55927cd4a6c960b98a27f424610"
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_last_msg_id": "8d728d3bcd5d46d69986d868c0580ff7"
   },
   "outputs": [],
   "source": [
    "x = spconv.SparseConvTensor(s_features, s_coords, spatial_shape, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_last_msg_id": "69f4662b9e2f45259512dc53cc1c1cb5"
   },
   "outputs": [],
   "source": [
    "s_conv = spconv.SparseConv2d(64, 64, 3, use_hash=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_last_msg_id": "f51f38d3468f4b6c8037e4dc2c5c25ed"
   },
   "outputs": [],
   "source": [
    "tmp = s_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_last_msg_id": "a229e5e5f9da4c598c6da5da3ca36928"
   },
   "outputs": [],
   "source": [
    "tmp = s_conv(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_last_msg_id": "3cd263deb32c4618859ec737874e45c0"
   },
   "outputs": [],
   "source": [
    "tmp = s_conv(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_last_msg_id": "631d737cceb24bf3890c0b05e998608b"
   },
   "outputs": [],
   "source": [
    "tmp = s_conv(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_last_msg_id": "88523cf2d6ec4ed48af6306db1869243"
   },
   "outputs": [],
   "source": [
    "s_pool = spconv.SparseMaxPool2d(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_last_msg_id": "41b89b358cec4e608df0af1c4375810d"
   },
   "outputs": [],
   "source": [
    "tmp = s_pool(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_last_msg_id": "5c0ffe28ac8147ac886e01b8dd4e889c"
   },
   "outputs": [],
   "source": [
    "x_dense_NCHW = tmp.dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "_last_msg_id": "540dc8c9cb1a46b1a343145d9ce5ec0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 718, 718])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_dense_NCHW.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "_last_msg_id": "03390e5d43e74d93819af6f598a97c3a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_dense_NCHW[0, 0].detach());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "_last_msg_id": "c1076c9b17dd4ff2881b7e03f1d7470c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(35.8602)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_dense_NCHW[1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = # your features with shape [N, numPlanes]\n",
    "indices = # your indices/coordinates with shape [N, ndim + 1], batch index must be put in indices[:, 0]\n",
    "spatial_shape = # spatial shape of your sparse tensor.\n",
    "batch_size = # batch size of your sparse tensor.\n",
    "x = spconv.SparseConvTensor(features, indices, spatial_shape, batch_size)\n",
    "x_dense_NCHW = x.dense() # convert sparse tensor to dense NCHW tensor.\n",
    "print(x.sparity) # helper function to check sparity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_last_msg_id": "7ba1000661564ec7850f1d2b1fb2c6b9"
   },
   "outputs": [],
   "source": [
    "from mmdet.ops import MaskedConv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_last_msg_id": "45abdf3926864c9c8a8c8f9da7f07356"
   },
   "outputs": [],
   "source": [
    "class StackMaskedConv2d(MaskedConv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, \n",
    "                 padding=0, dilation=1, groups=1, bias=True):\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride, \n",
    "                         padding, dilation, groups, bias)\n",
    "\n",
    "    def forward(self, x, masks):\n",
    "        out = []\n",
    "        for b in range(x.shape[0]):\n",
    "            out.append(super().forward(x[b][None, ...], masks[b][None, ...]))\n",
    "        return torch.cat(out, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_last_msg_id": "c2d01fba63ab467c85614399a2eff842"
   },
   "outputs": [],
   "source": [
    "m_conv = StackMaskedConv2d(64, 64, 3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_last_msg_id": "d553ce55229e41d180d31fbcd612ab1e"
   },
   "outputs": [],
   "source": [
    "x_masks = ~(x_map == 0).all(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_last_msg_id": "7136cb7b2e394f2287d32ea7105339e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1587428266983/work/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of addmm is deprecated:\n",
      "\taddmm(Number beta, Tensor input, Number alpha, Tensor mat1, Tensor mat2, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddmm(Tensor input, Tensor mat1, Tensor mat2, *, Number beta, Number alpha, Tensor out)\n"
     ]
    }
   ],
   "source": [
    "tmp = m_conv(x_map, x_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_last_msg_id": "b841bbf4acc2415d989b80e51fe99d2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64, 558, 318])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_last_msg_id": "af19ebb5e42a4b718db023a9214be9c9"
   },
   "outputs": [],
   "source": [
    "x_masks = ~(tmp == 0).all(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_last_msg_id": "92c30ccad78c411087d50072f74f4887"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.68 GiB (GPU 1; 10.92 GiB total capacity; 8.45 GiB already allocated; 1.84 GiB free; 8.55 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-6b4525bf1fa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtmp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-6d20f49d63cf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, masks)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.68 GiB (GPU 1; 10.92 GiB total capacity; 8.45 GiB already allocated; 1.84 GiB free; 8.55 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "tmp2 = m_conv(tmp, x_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_last_msg_id": "a613865789754d408945e72c0933bb91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64, 560, 320])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_last_msg_id": "c76fbaf1c1fc40cabd80ad5f80c3923d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_last_msg_id": "84ed3d9e861e48c58e6f172c45bdd091"
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "f_d_rate = 0.0\n",
    "d_rate = 0.0\n",
    "\n",
    "max_height = 70\n",
    "max_width = 40\n",
    "\n",
    "class MainModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.f_map = FeaturesMap(False, 64, max_height, max_width, f_size=8)\n",
    "        \n",
    "        # self.backbone = models.resnext50_32x4d(pretrained=False)\n",
    "        self.backbone = models.resnet18(pretrained=False)\n",
    "        '''\n",
    "        self.backbone.conv1 = nn.Sequential(\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 1),\n",
    "        )\n",
    "        '''\n",
    "        self.backbone.conv1 = nn.Identity()\n",
    "        # self.backbone.fc = nn.Linear(2048, 512)\n",
    "        self.backbone.fc = nn.Linear(512, 512)\n",
    "        self.backbone.maxpool = nn.Identity()\n",
    "        \n",
    "        self.reg_linear = nn.Linear(512, 1)\n",
    "        self.class_linear = nn.Linear(512, max_lbl_nums)\n",
    "\n",
    "    def forward(self, features, ys, xs):\n",
    "        f_map = self.f_map(features, ys, xs)\n",
    "        x = self.backbone(f_map)\n",
    "        return self.reg_linear(x), self.class_linear(x)\n",
    "\n",
    "model = MainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_last_msg_id": "5d6bcc08805c4c939a57b8d537aab997"
   },
   "outputs": [],
   "source": [
    "# model.backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_last_msg_id": "30274e08e87747b5bfd530ed7085978a"
   },
   "outputs": [],
   "source": [
    "#from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_last_msg_id": "e2f1b4869ed04b45841c885260b1f813"
   },
   "outputs": [],
   "source": [
    "#summary(model.backbone, (64, 70*8, 40*8), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_last_msg_id": "ebd17b2656a74c7e9846fe582044de01"
   },
   "outputs": [],
   "source": [
    "module = WSIModuleV1(model, hparams, log_train_every_batch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_last_msg_id": "0b02145e673441bbab548f17fa75dd97"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:GPU available: True, used: True\n",
      "INFO:lightning:CUDA_VISIBLE_DEVICES: [1]\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(max_epochs=hparams['epochs'], gpus=[1,], fast_dev_run=False, num_sanity_val_steps=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_last_msg_id": "04457fdd7c5747658488978346eb17e7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:\n",
      "   | Name                                 | Type              | Params\n",
      "-----------------------------------------------------------------------\n",
      "0  | model                                | MainModel         | 11 M  \n",
      "1  | model.f_map                          | FeaturesMap       | 0     \n",
      "2  | model.backbone                       | ResNet            | 11 M  \n",
      "3  | model.backbone.conv1                 | Identity          | 0     \n",
      "4  | model.backbone.bn1                   | BatchNorm2d       | 128   \n",
      "5  | model.backbone.relu                  | ReLU              | 0     \n",
      "6  | model.backbone.maxpool               | Identity          | 0     \n",
      "7  | model.backbone.layer1                | Sequential        | 147 K \n",
      "8  | model.backbone.layer1.0              | BasicBlock        | 73 K  \n",
      "9  | model.backbone.layer1.0.conv1        | Conv2d            | 36 K  \n",
      "10 | model.backbone.layer1.0.bn1          | BatchNorm2d       | 128   \n",
      "11 | model.backbone.layer1.0.relu         | ReLU              | 0     \n",
      "12 | model.backbone.layer1.0.conv2        | Conv2d            | 36 K  \n",
      "13 | model.backbone.layer1.0.bn2          | BatchNorm2d       | 128   \n",
      "14 | model.backbone.layer1.1              | BasicBlock        | 73 K  \n",
      "15 | model.backbone.layer1.1.conv1        | Conv2d            | 36 K  \n",
      "16 | model.backbone.layer1.1.bn1          | BatchNorm2d       | 128   \n",
      "17 | model.backbone.layer1.1.relu         | ReLU              | 0     \n",
      "18 | model.backbone.layer1.1.conv2        | Conv2d            | 36 K  \n",
      "19 | model.backbone.layer1.1.bn2          | BatchNorm2d       | 128   \n",
      "20 | model.backbone.layer2                | Sequential        | 525 K \n",
      "21 | model.backbone.layer2.0              | BasicBlock        | 230 K \n",
      "22 | model.backbone.layer2.0.conv1        | Conv2d            | 73 K  \n",
      "23 | model.backbone.layer2.0.bn1          | BatchNorm2d       | 256   \n",
      "24 | model.backbone.layer2.0.relu         | ReLU              | 0     \n",
      "25 | model.backbone.layer2.0.conv2        | Conv2d            | 147 K \n",
      "26 | model.backbone.layer2.0.bn2          | BatchNorm2d       | 256   \n",
      "27 | model.backbone.layer2.0.downsample   | Sequential        | 8 K   \n",
      "28 | model.backbone.layer2.0.downsample.0 | Conv2d            | 8 K   \n",
      "29 | model.backbone.layer2.0.downsample.1 | BatchNorm2d       | 256   \n",
      "30 | model.backbone.layer2.1              | BasicBlock        | 295 K \n",
      "31 | model.backbone.layer2.1.conv1        | Conv2d            | 147 K \n",
      "32 | model.backbone.layer2.1.bn1          | BatchNorm2d       | 256   \n",
      "33 | model.backbone.layer2.1.relu         | ReLU              | 0     \n",
      "34 | model.backbone.layer2.1.conv2        | Conv2d            | 147 K \n",
      "35 | model.backbone.layer2.1.bn2          | BatchNorm2d       | 256   \n",
      "36 | model.backbone.layer3                | Sequential        | 2 M   \n",
      "37 | model.backbone.layer3.0              | BasicBlock        | 919 K \n",
      "38 | model.backbone.layer3.0.conv1        | Conv2d            | 294 K \n",
      "39 | model.backbone.layer3.0.bn1          | BatchNorm2d       | 512   \n",
      "40 | model.backbone.layer3.0.relu         | ReLU              | 0     \n",
      "41 | model.backbone.layer3.0.conv2        | Conv2d            | 589 K \n",
      "42 | model.backbone.layer3.0.bn2          | BatchNorm2d       | 512   \n",
      "43 | model.backbone.layer3.0.downsample   | Sequential        | 33 K  \n",
      "44 | model.backbone.layer3.0.downsample.0 | Conv2d            | 32 K  \n",
      "45 | model.backbone.layer3.0.downsample.1 | BatchNorm2d       | 512   \n",
      "46 | model.backbone.layer3.1              | BasicBlock        | 1 M   \n",
      "47 | model.backbone.layer3.1.conv1        | Conv2d            | 589 K \n",
      "48 | model.backbone.layer3.1.bn1          | BatchNorm2d       | 512   \n",
      "49 | model.backbone.layer3.1.relu         | ReLU              | 0     \n",
      "50 | model.backbone.layer3.1.conv2        | Conv2d            | 589 K \n",
      "51 | model.backbone.layer3.1.bn2          | BatchNorm2d       | 512   \n",
      "52 | model.backbone.layer4                | Sequential        | 8 M   \n",
      "53 | model.backbone.layer4.0              | BasicBlock        | 3 M   \n",
      "54 | model.backbone.layer4.0.conv1        | Conv2d            | 1 M   \n",
      "55 | model.backbone.layer4.0.bn1          | BatchNorm2d       | 1 K   \n",
      "56 | model.backbone.layer4.0.relu         | ReLU              | 0     \n",
      "57 | model.backbone.layer4.0.conv2        | Conv2d            | 2 M   \n",
      "58 | model.backbone.layer4.0.bn2          | BatchNorm2d       | 1 K   \n",
      "59 | model.backbone.layer4.0.downsample   | Sequential        | 132 K \n",
      "60 | model.backbone.layer4.0.downsample.0 | Conv2d            | 131 K \n",
      "61 | model.backbone.layer4.0.downsample.1 | BatchNorm2d       | 1 K   \n",
      "62 | model.backbone.layer4.1              | BasicBlock        | 4 M   \n",
      "63 | model.backbone.layer4.1.conv1        | Conv2d            | 2 M   \n",
      "64 | model.backbone.layer4.1.bn1          | BatchNorm2d       | 1 K   \n",
      "65 | model.backbone.layer4.1.relu         | ReLU              | 0     \n",
      "66 | model.backbone.layer4.1.conv2        | Conv2d            | 2 M   \n",
      "67 | model.backbone.layer4.1.bn2          | BatchNorm2d       | 1 K   \n",
      "68 | model.backbone.avgpool               | AdaptiveAvgPool2d | 0     \n",
      "69 | model.backbone.fc                    | Linear            | 262 K \n",
      "70 | model.reg_linear                     | Linear            | 513   \n",
      "71 | model.class_linear                   | Linear            | 3 K   \n",
      "72 | reg_loss                             | MSELoss           | 0     \n",
      "73 | class_loss                           | SmoothLoss        | 0     \n",
      "74 | class_loss.criterion                 | KLDivLoss         | 0     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    initial_lr: 0.00025\n",
      "    lr: 0.00025\n",
      "    weight_decay: 0.0001\n",
      ")] [{'interval': 'epoch', 'scheduler': <lib.schedulers.DelayedScheduler object at 0x7fd8066486d0>}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/anaconda3/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:23: RuntimeWarning: Displayed epoch numbers in the progress bar start from \"1\" until v0.6.x, but will start from \"0\" in v0.8.0.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5116c69a824d5ba37297eb88e958db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:2247: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "INFO:lightning:Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(module, train_loader, val_loader)\n",
    "trainer.save_checkpoint(os.path.join(trainer.checkpoint_callback.dirpath,\n",
    "                                     \"last.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
