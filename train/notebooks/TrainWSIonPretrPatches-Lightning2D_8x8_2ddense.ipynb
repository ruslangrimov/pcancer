{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_last_msg_id": "dc03c22032014a6e86e846bb1b05c4e6"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_last_msg_id": "2b426de0b0454a488cfb31ae596a7cef"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import psutil\n",
    "\n",
    "import random\n",
    "import math\n",
    "from functools import partial\n",
    "\n",
    "import torch \n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import multiprocessing.dummy as mp\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.core import LightningModule\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers.tensorboard import TensorBoardLogger\n",
    "\n",
    "\n",
    "from lib.schedulers import DelayedScheduler\n",
    "from lib.datasets import (max_lbl_nums, actual_lbl_nums, \n",
    "                          patches_rgb_mean_av1, patches_rgb_std_av1, \n",
    "                          get_train_test_img_ids_split)\n",
    "from lib.dataloaders import PatchesDataset, WSIPatchesDatasetRaw, WSIPatchesDummyDataloader\n",
    "from lib.augmentations import augment_v1_clr_only, augment_empty_clr_only\n",
    "from lib.losses import SmoothLoss\n",
    "from lib.trainers import WSIModuleV1\n",
    "\n",
    "from lib.models.unetv1 import get_model\n",
    "from lib.models.features_map import FeaturesMap\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_last_msg_id": "e1bb88e528684bf68f41359961322d76"
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "# from lib.datasets import patches_csv_path, patches_path\n",
    "from lib.datasets import (patches_clean90_csv_path as patches_csv_path, patches_path,\n",
    "                          patches_clean90_pkl_path as patches_pkl_path)\n",
    "# from lib.dataloaders import imread, get_g_score_num, get_provider_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_last_msg_id": "2e4a53a2c38a45c89ba3d724983336a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e8baa3bb9dcfb9cef5ca599d62bb8046',\n",
       " '9b2948ff81b64677a1a152a1532c1a50',\n",
       " '5b003d43ec0ce5979062442486f84cf7',\n",
       " '375b2c9501320b35ceb638a3274812aa']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img_ids, test_img_ids = get_train_test_img_ids_split()\n",
    "\n",
    "test_img_ids[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_last_msg_id": "f5e6891667424004995f957d54ffa1f6"
   },
   "outputs": [],
   "source": [
    "from lib.dataloaders import WSIPatchesDataloader, WSIPatchesDatasetRaw\n",
    "from lib.utils import get_pretrained_model, get_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_last_msg_id": "9ac846e7e20943e3801169003cee7b35"
   },
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_last_msg_id": "b0c67b8120dc4a68859bdef8c1af22e8"
   },
   "outputs": [],
   "source": [
    "train_batch_path = '/mnt/SSDData/pdata/processed/pretrained_64x8x8/train/{}/'\n",
    "test_batch_path = '/mnt/SSDData/pdata/processed/pretrained_64x8x8/val/'\n",
    "\n",
    "train_loader = WSIPatchesDummyDataloader(train_batch_path, precalc_epochs=11, batch_size=batch_size, shuffle=True)\n",
    "val_loader = WSIPatchesDummyDataloader(test_batch_path, precalc_epochs=11, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_last_msg_id": "8c9a83b26c324cf88a1fac7f61063855"
   },
   "outputs": [],
   "source": [
    "steps_in_epoh = 1\n",
    "\n",
    "epochs = 90\n",
    "\n",
    "warmup_epochs = 0\n",
    "warmup_steps = 0\n",
    "\n",
    "\n",
    "hparams = {\n",
    "    'module': {\n",
    "        'name': 'lib.trainers.WSIModuleV1',\n",
    "        'params': {\n",
    "            'model': {\n",
    "                'name': 'lib.models.wsi_resnets.Resnet_512x1x1',\n",
    "                'params': {\n",
    "                    'backbone': 'resnet18',\n",
    "                    'backbone_features': 512,\n",
    "                    'classes': max_lbl_nums,\n",
    "                    'features_do': 0,\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    'batch_size': batch_size,\n",
    "    'learning_rate': 0.001 * 16 / 256,\n",
    "    'dataset': {\n",
    "        'dataloader': 'dummy',\n",
    "        'rgb_mean': patches_rgb_mean_av1,\n",
    "        'rgb_std': patches_rgb_std_av1,\n",
    "        'classes': max_lbl_nums,\n",
    "        'precalc_epochs': 11,\n",
    "        'train_test_split': {},\n",
    "    },\n",
    "    'optimizer': {\n",
    "        'name': 'torch.optim.Adam',\n",
    "        'params': {\n",
    "            'weight_decay': 1e-4\n",
    "        }\n",
    "    },\n",
    "    'scheduler': {\n",
    "        'name': 'torch.optim.lr_scheduler.ExponentialLR',\n",
    "        'params': {\n",
    "            'gamma': 0.96,\n",
    "        },\n",
    "        'interval': 'epoch'\n",
    "    },\n",
    "    'loss': {\n",
    "        'weights': {\n",
    "            'reg': 1 / 2,\n",
    "            'class': 9 / 2\n",
    "        },\n",
    "        'label_smoothing': 0.1\n",
    "    },\n",
    "    'warmup_steps': warmup_steps,\n",
    "    'steps_in_epoh': steps_in_epoh,\n",
    "    'epochs': epochs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_last_msg_id": "e5ae9c8a4f274fc58cba59bba5fa35c4"
   },
   "outputs": [],
   "source": [
    "steps_in_epoh = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_last_msg_id": "5d2c803909bc4eaf99ff405fffdccc44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1053"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_in_epoh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_last_msg_id": "9a4967b9ec45425c82f88a06bd8080c3"
   },
   "outputs": [],
   "source": [
    "hparams['steps_in_batch'] = steps_in_epoh\n",
    "if 'T_max' in hparams['scheduler']['params']:\n",
    "    hparams['scheduler']['params']['T_max'] = (epochs * steps_in_epoh -\n",
    "                                               warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_last_msg_id": "8649abba164c4f2db7bab52423e44349"
   },
   "outputs": [],
   "source": [
    "# tmp[0].shape\n",
    "# torch.Size([64, 300, 64, 8, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_last_msg_id": "643d21e0d4a0475187227340b1115566"
   },
   "outputs": [],
   "source": [
    "class FeaturesMap(nn.Module):\n",
    "    def __init__(self, use_dummy_feature, f_channels=512, max_height=70,\n",
    "                 max_width=40, f_size=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.f_size = f_size\n",
    "        self.max_height = max_height * self.f_size\n",
    "        self.max_width = max_width * self.f_size\n",
    "        self.f_channels = f_channels\n",
    "        self.use_dummy_feature = use_dummy_feature\n",
    "        \n",
    "        if self.use_dummy_feature:\n",
    "            self.backend_feature =\\\n",
    "                nn.Parameter(torch.full((self.f_channels, 1, 1), 0))\n",
    "\n",
    "    def forward(self, features, ys, xs, validation=None):\n",
    "        if validation is None:\n",
    "            validation = not self.training\n",
    "\n",
    "        b_sz = features.shape[0]\n",
    "\n",
    "        if self.use_dummy_feature:\n",
    "            f_map = self.backend_feature.expand(self.f_channels,\n",
    "                                                self.max_height,\n",
    "                                                self.max_width)\n",
    "        else:\n",
    "            f_map = torch.full((self.f_channels, self.max_height,\n",
    "                                self.max_width), 0,\n",
    "                               dtype=features.dtype, device=features.device)\n",
    "\n",
    "        res_f_maps = []\n",
    "        for b in range(b_sz):\n",
    "            real_mask = ys[b] > -1\n",
    "\n",
    "            min_y, max_y = (ys[b, real_mask].min().item(),\n",
    "                            ys[b, real_mask].max().item())\n",
    "            min_x, max_x = (xs[b, real_mask].min().item(),\n",
    "                            xs[b, real_mask].max().item())\n",
    "            \n",
    "            height = (max_y - min_y + 1) * self.f_size\n",
    "            width = (max_x - min_x + 1) * self.f_size\n",
    "\n",
    "            tmp_f_map = torch.full((self.f_channels, height, width), -1,\n",
    "                                   dtype=features.dtype,\n",
    "                                   device=features.device)\n",
    "\n",
    "            if self.f_size == 1:\n",
    "                tmp_f_map[:, ys[b, real_mask] - min_y, xs[b, real_mask] - min_x] =\\\n",
    "                    features[b, :, real_mask]\n",
    "            else:\n",
    "                for n in range(real_mask.sum().item()):\n",
    "                    t = features[b, n]\n",
    "                    _y = ys[b, n] - min_y\n",
    "                    _x = xs[b, n] - min_x                    \n",
    "                    tmp_f_map[:, _y*self.f_size:(_y+1)*self.f_size, \n",
    "                                 _x*self.f_size:(_x+1)*self.f_size] = t\n",
    "\n",
    "            if width > height:\n",
    "                tmp_f_map = tmp_f_map.transpose(-1, -2)\n",
    "\n",
    "            _, height, width = tmp_f_map.shape\n",
    "            # print(height, width)\n",
    "\n",
    "            h_dif = height - self.max_height\n",
    "            w_dif = width - self.max_width\n",
    "\n",
    "            if h_dif > 0:\n",
    "                cut_top = (math.ceil(h_dif / 2) if validation else\n",
    "                           random.randint(0, h_dif))\n",
    "                cut_bottom = -(h_dif - cut_top)\n",
    "                if cut_bottom >= 0:\n",
    "                    cut_bottom = None\n",
    "                pad_top, pad_bottom = 0, 0\n",
    "            else:\n",
    "                pad_top = (math.ceil(-h_dif / 2) if validation else\n",
    "                           random.randint(0, -h_dif))\n",
    "                pad_bottom = -h_dif - pad_top\n",
    "                cut_top, cut_bottom = 0, None\n",
    "\n",
    "            if w_dif > 0:\n",
    "                cut_left = (math.ceil(w_dif / 2) if validation else\n",
    "                            random.randint(0, w_dif))\n",
    "                cut_right = -(w_dif - cut_left)\n",
    "                if cut_right >= 0:\n",
    "                    cut_right = None\n",
    "                pad_right, pad_left = 0, 0\n",
    "            else:\n",
    "                pad_right = (math.ceil(-w_dif / 2) if validation else\n",
    "                             random.randint(0, -w_dif))\n",
    "                pad_left = -w_dif - pad_right\n",
    "                cut_left, cut_right = 0, None\n",
    "\n",
    "            if not validation:\n",
    "                if random.random() > 0.5:\n",
    "                    tmp_f_map = torch.flip(tmp_f_map, [-1])\n",
    "\n",
    "                if random.random() > 0.5:\n",
    "                    tmp_f_map = torch.flip(tmp_f_map, [-2])\n",
    "\n",
    "            tmp_f_map = F.pad(tmp_f_map[:, cut_top:cut_bottom,\n",
    "                                        cut_left:cut_right],\n",
    "                              (pad_right, pad_left,\n",
    "                               pad_top, pad_bottom), value=-1)\n",
    "\n",
    "            real_2d_mask = (tmp_f_map != -1).all(dim=0)\n",
    "\n",
    "            # print(real_2d_mask.shape, f_map.shape, tmp_f_map.shape)\n",
    "\n",
    "            res_f_map = (~real_2d_mask) * f_map + real_2d_mask * tmp_f_map\n",
    "            res_f_maps.append(res_f_map)\n",
    "\n",
    "        return torch.stack(res_f_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_last_msg_id": "3fd80746cefc41d486b6c565379ed67e"
   },
   "outputs": [],
   "source": [
    "#features, ys, xs, provider, isup_grade, gleason_score = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_last_msg_id": "aefbd9e4b04243da83529ec41bcfdc2f"
   },
   "outputs": [],
   "source": [
    "#f_map = FeaturesMap(False, 64, 70, 40, f_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_last_msg_id": "137bf38c17314ec3913d815736c24eb3"
   },
   "outputs": [],
   "source": [
    "#device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_last_msg_id": "a24f99864b534eacb4995d8aced8df5a"
   },
   "outputs": [],
   "source": [
    "# features, ys, xs = features.to(device), ys.to(device), xs.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_last_msg_id": "3f78f933e11146cf8dbe39ceb76d2fc3"
   },
   "outputs": [],
   "source": [
    "# tmp = f_map(features, ys, xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_last_msg_id": "c76fbaf1c1fc40cabd80ad5f80c3923d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_last_msg_id": "9148c393adb4456c9978496a1b61e8d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1587428266983/work/aten/src/ATen/native/TensorFactories.cpp:361: UserWarning: Deprecation warning: In a future PyTorch release torch.full will no longer return tensors of floating dtype by default. Instead, a bool fill_value will return a tensor of torch.bool dtype, and an integral fill_value will return a tensor of torch.long dtype. Set the optional `dtype` or `out` arguments to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "f_d_rate = 0.0\n",
    "d_rate = 0.0\n",
    "\n",
    "max_height = 70\n",
    "max_width = 40\n",
    "\n",
    "class MainModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.f_map = FeaturesMap(True, 64, max_height, max_width, f_size=8)\n",
    "        \n",
    "        # self.backbone = models.resnext50_32x4d(pretrained=False)\n",
    "        self.backbone = models.resnet18(pretrained=False)\n",
    "        self.backbone.conv1 = nn.Sequential(\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 1),\n",
    "        )\n",
    "        #self.backbone.conv1 = nn.Identity()\n",
    "        # self.backbone.fc = nn.Linear(2048, 512)\n",
    "        self.backbone.fc = nn.Linear(512, 512)\n",
    "        self.backbone.maxpool = nn.Identity()\n",
    "        \n",
    "        self.reg_linear = nn.Linear(512, 1)\n",
    "        self.class_linear = nn.Linear(512, max_lbl_nums)\n",
    "\n",
    "    def forward(self, features, ys, xs):\n",
    "        f_map = self.f_map(features, ys, xs)\n",
    "        x = self.backbone(f_map)\n",
    "        return self.reg_linear(x), self.class_linear(x)\n",
    "\n",
    "model = MainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_last_msg_id": "11fd48473bb346b29edaf185f1f410c2"
   },
   "outputs": [],
   "source": [
    "# model.backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_last_msg_id": "a21ea993b15b4f4b81013b070113acc2"
   },
   "outputs": [],
   "source": [
    "#from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_last_msg_id": "9c1d7a3264f94f47b97bda1e2ddb0af9"
   },
   "outputs": [],
   "source": [
    "#summary(model.backbone, (64, 70*8, 40*8), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_last_msg_id": "70f14c3173994b67991e05c19fc757fb"
   },
   "outputs": [],
   "source": [
    "module = WSIModuleV1(model, hparams, log_train_every_batch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_last_msg_id": "07d6262c0949481c885dfa83865bc220"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:GPU available: True, used: True\n",
      "INFO:lightning:CUDA_VISIBLE_DEVICES: [1]\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(max_epochs=hparams['epochs'], gpus=[1,], fast_dev_run=False, num_sanity_val_steps=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_last_msg_id": "bebd3ea7e06045d498f35c986d6f90a6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:\n",
      "   | Name                                 | Type              | Params\n",
      "-----------------------------------------------------------------------\n",
      "0  | model                                | MainModel         | 11 M  \n",
      "1  | model.f_map                          | FeaturesMap       | 64    \n",
      "2  | model.backbone                       | ResNet            | 11 M  \n",
      "3  | model.backbone.conv1                 | Sequential        | 12 K  \n",
      "4  | model.backbone.conv1.0               | BatchNorm2d       | 128   \n",
      "5  | model.backbone.conv1.1               | Conv2d            | 4 K   \n",
      "6  | model.backbone.conv1.2               | BatchNorm2d       | 128   \n",
      "7  | model.backbone.conv1.3               | ReLU              | 0     \n",
      "8  | model.backbone.conv1.4               | Conv2d            | 4 K   \n",
      "9  | model.backbone.conv1.5               | BatchNorm2d       | 128   \n",
      "10 | model.backbone.conv1.6               | ReLU              | 0     \n",
      "11 | model.backbone.conv1.7               | Conv2d            | 4 K   \n",
      "12 | model.backbone.bn1                   | BatchNorm2d       | 128   \n",
      "13 | model.backbone.relu                  | ReLU              | 0     \n",
      "14 | model.backbone.maxpool               | Identity          | 0     \n",
      "15 | model.backbone.layer1                | Sequential        | 147 K \n",
      "16 | model.backbone.layer1.0              | BasicBlock        | 73 K  \n",
      "17 | model.backbone.layer1.0.conv1        | Conv2d            | 36 K  \n",
      "18 | model.backbone.layer1.0.bn1          | BatchNorm2d       | 128   \n",
      "19 | model.backbone.layer1.0.relu         | ReLU              | 0     \n",
      "20 | model.backbone.layer1.0.conv2        | Conv2d            | 36 K  \n",
      "21 | model.backbone.layer1.0.bn2          | BatchNorm2d       | 128   \n",
      "22 | model.backbone.layer1.1              | BasicBlock        | 73 K  \n",
      "23 | model.backbone.layer1.1.conv1        | Conv2d            | 36 K  \n",
      "24 | model.backbone.layer1.1.bn1          | BatchNorm2d       | 128   \n",
      "25 | model.backbone.layer1.1.relu         | ReLU              | 0     \n",
      "26 | model.backbone.layer1.1.conv2        | Conv2d            | 36 K  \n",
      "27 | model.backbone.layer1.1.bn2          | BatchNorm2d       | 128   \n",
      "28 | model.backbone.layer2                | Sequential        | 525 K \n",
      "29 | model.backbone.layer2.0              | BasicBlock        | 230 K \n",
      "30 | model.backbone.layer2.0.conv1        | Conv2d            | 73 K  \n",
      "31 | model.backbone.layer2.0.bn1          | BatchNorm2d       | 256   \n",
      "32 | model.backbone.layer2.0.relu         | ReLU              | 0     \n",
      "33 | model.backbone.layer2.0.conv2        | Conv2d            | 147 K \n",
      "34 | model.backbone.layer2.0.bn2          | BatchNorm2d       | 256   \n",
      "35 | model.backbone.layer2.0.downsample   | Sequential        | 8 K   \n",
      "36 | model.backbone.layer2.0.downsample.0 | Conv2d            | 8 K   \n",
      "37 | model.backbone.layer2.0.downsample.1 | BatchNorm2d       | 256   \n",
      "38 | model.backbone.layer2.1              | BasicBlock        | 295 K \n",
      "39 | model.backbone.layer2.1.conv1        | Conv2d            | 147 K \n",
      "40 | model.backbone.layer2.1.bn1          | BatchNorm2d       | 256   \n",
      "41 | model.backbone.layer2.1.relu         | ReLU              | 0     \n",
      "42 | model.backbone.layer2.1.conv2        | Conv2d            | 147 K \n",
      "43 | model.backbone.layer2.1.bn2          | BatchNorm2d       | 256   \n",
      "44 | model.backbone.layer3                | Sequential        | 2 M   \n",
      "45 | model.backbone.layer3.0              | BasicBlock        | 919 K \n",
      "46 | model.backbone.layer3.0.conv1        | Conv2d            | 294 K \n",
      "47 | model.backbone.layer3.0.bn1          | BatchNorm2d       | 512   \n",
      "48 | model.backbone.layer3.0.relu         | ReLU              | 0     \n",
      "49 | model.backbone.layer3.0.conv2        | Conv2d            | 589 K \n",
      "50 | model.backbone.layer3.0.bn2          | BatchNorm2d       | 512   \n",
      "51 | model.backbone.layer3.0.downsample   | Sequential        | 33 K  \n",
      "52 | model.backbone.layer3.0.downsample.0 | Conv2d            | 32 K  \n",
      "53 | model.backbone.layer3.0.downsample.1 | BatchNorm2d       | 512   \n",
      "54 | model.backbone.layer3.1              | BasicBlock        | 1 M   \n",
      "55 | model.backbone.layer3.1.conv1        | Conv2d            | 589 K \n",
      "56 | model.backbone.layer3.1.bn1          | BatchNorm2d       | 512   \n",
      "57 | model.backbone.layer3.1.relu         | ReLU              | 0     \n",
      "58 | model.backbone.layer3.1.conv2        | Conv2d            | 589 K \n",
      "59 | model.backbone.layer3.1.bn2          | BatchNorm2d       | 512   \n",
      "60 | model.backbone.layer4                | Sequential        | 8 M   \n",
      "61 | model.backbone.layer4.0              | BasicBlock        | 3 M   \n",
      "62 | model.backbone.layer4.0.conv1        | Conv2d            | 1 M   \n",
      "63 | model.backbone.layer4.0.bn1          | BatchNorm2d       | 1 K   \n",
      "64 | model.backbone.layer4.0.relu         | ReLU              | 0     \n",
      "65 | model.backbone.layer4.0.conv2        | Conv2d            | 2 M   \n",
      "66 | model.backbone.layer4.0.bn2          | BatchNorm2d       | 1 K   \n",
      "67 | model.backbone.layer4.0.downsample   | Sequential        | 132 K \n",
      "68 | model.backbone.layer4.0.downsample.0 | Conv2d            | 131 K \n",
      "69 | model.backbone.layer4.0.downsample.1 | BatchNorm2d       | 1 K   \n",
      "70 | model.backbone.layer4.1              | BasicBlock        | 4 M   \n",
      "71 | model.backbone.layer4.1.conv1        | Conv2d            | 2 M   \n",
      "72 | model.backbone.layer4.1.bn1          | BatchNorm2d       | 1 K   \n",
      "73 | model.backbone.layer4.1.relu         | ReLU              | 0     \n",
      "74 | model.backbone.layer4.1.conv2        | Conv2d            | 2 M   \n",
      "75 | model.backbone.layer4.1.bn2          | BatchNorm2d       | 1 K   \n",
      "76 | model.backbone.avgpool               | AdaptiveAvgPool2d | 0     \n",
      "77 | model.backbone.fc                    | Linear            | 262 K \n",
      "78 | model.reg_linear                     | Linear            | 513   \n",
      "79 | model.class_linear                   | Linear            | 3 K   \n",
      "80 | reg_loss                             | MSELoss           | 0     \n",
      "81 | class_loss                           | SmoothLoss        | 0     \n",
      "82 | class_loss.criterion                 | KLDivLoss         | 0     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    initial_lr: 6.25e-05\n",
      "    lr: 6.25e-05\n",
      "    weight_decay: 0.0001\n",
      ")] [{'interval': 'epoch', 'scheduler': <lib.schedulers.DelayedScheduler object at 0x7fdcafb7fe10>}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/anaconda3/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:23: RuntimeWarning: Displayed epoch numbers in the progress bar start from \"1\" until v0.6.x, but will start from \"0\" in v0.8.0.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e99bc42387428998a3987a34495012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:2247: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "INFO:lightning:Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(module, train_loader, val_loader)\n",
    "trainer.save_checkpoint(os.path.join(trainer.checkpoint_callback.dirpath,\n",
    "                                     \"last.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
